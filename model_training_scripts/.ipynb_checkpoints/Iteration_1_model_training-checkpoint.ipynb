{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dad345d",
   "metadata": {},
   "source": [
    "Import packages required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af34ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e51b39",
   "metadata": {},
   "source": [
    "Get meta data of all the images available in the ISIC website that we can use to train and test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63cc575a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>public</th>\n",
       "      <th>copyright_license</th>\n",
       "      <th>attribution</th>\n",
       "      <th>metadata</th>\n",
       "      <th>files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_6230191</td>\n",
       "      <td>True</td>\n",
       "      <td>CC-BY-NC</td>\n",
       "      <td>Hospital Italiano de Buenos Aires</td>\n",
       "      <td>{'acquisition': {'pixels_x': 640, 'pixels_y': ...</td>\n",
       "      <td>{'full': {'url': 'https://content.isic-archive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_4485929</td>\n",
       "      <td>True</td>\n",
       "      <td>CC-BY-NC</td>\n",
       "      <td>Hospital Italiano de Buenos Aires</td>\n",
       "      <td>{'acquisition': {'pixels_x': 2448, 'pixels_y':...</td>\n",
       "      <td>{'full': {'url': 'https://content.isic-archive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_3079785</td>\n",
       "      <td>True</td>\n",
       "      <td>CC-BY-NC</td>\n",
       "      <td>Hospital Italiano de Buenos Aires</td>\n",
       "      <td>{'acquisition': {'pixels_x': 640, 'pixels_y': ...</td>\n",
       "      <td>{'full': {'url': 'https://content.isic-archive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_9677008</td>\n",
       "      <td>True</td>\n",
       "      <td>CC-BY-NC</td>\n",
       "      <td>Hospital Italiano de Buenos Aires</td>\n",
       "      <td>{'acquisition': {'pixels_x': 1409, 'pixels_y':...</td>\n",
       "      <td>{'full': {'url': 'https://content.isic-archive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_9129115</td>\n",
       "      <td>True</td>\n",
       "      <td>CC-BY-NC</td>\n",
       "      <td>Hospital Italiano de Buenos Aires</td>\n",
       "      <td>{'acquisition': {'pixels_x': 498, 'pixels_y': ...</td>\n",
       "      <td>{'full': {'url': 'https://content.isic-archive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73300</th>\n",
       "      <td>ISIC_0000004</td>\n",
       "      <td>True</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>{'acquisition': {'pixels_x': 1022, 'pixels_y':...</td>\n",
       "      <td>{'full': {'url': 'https://content.isic-archive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73301</th>\n",
       "      <td>ISIC_0000003</td>\n",
       "      <td>True</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>{'acquisition': {'pixels_x': 1022, 'pixels_y':...</td>\n",
       "      <td>{'full': {'url': 'https://content.isic-archive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73302</th>\n",
       "      <td>ISIC_0000002</td>\n",
       "      <td>True</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>{'acquisition': {'pixels_x': 1022, 'pixels_y':...</td>\n",
       "      <td>{'full': {'url': 'https://content.isic-archive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73303</th>\n",
       "      <td>ISIC_0000001</td>\n",
       "      <td>True</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>{'acquisition': {'pixels_x': 1022, 'pixels_y':...</td>\n",
       "      <td>{'full': {'url': 'https://content.isic-archive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73304</th>\n",
       "      <td>ISIC_0000000</td>\n",
       "      <td>True</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>{'acquisition': {'pixels_x': 1022, 'pixels_y':...</td>\n",
       "      <td>{'full': {'url': 'https://content.isic-archive...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73305 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            isic_id  public copyright_license  \\\n",
       "0      ISIC_6230191    True          CC-BY-NC   \n",
       "1      ISIC_4485929    True          CC-BY-NC   \n",
       "2      ISIC_3079785    True          CC-BY-NC   \n",
       "3      ISIC_9677008    True          CC-BY-NC   \n",
       "4      ISIC_9129115    True          CC-BY-NC   \n",
       "...             ...     ...               ...   \n",
       "73300  ISIC_0000004    True              CC-0   \n",
       "73301  ISIC_0000003    True              CC-0   \n",
       "73302  ISIC_0000002    True              CC-0   \n",
       "73303  ISIC_0000001    True              CC-0   \n",
       "73304  ISIC_0000000    True              CC-0   \n",
       "\n",
       "                             attribution  \\\n",
       "0      Hospital Italiano de Buenos Aires   \n",
       "1      Hospital Italiano de Buenos Aires   \n",
       "2      Hospital Italiano de Buenos Aires   \n",
       "3      Hospital Italiano de Buenos Aires   \n",
       "4      Hospital Italiano de Buenos Aires   \n",
       "...                                  ...   \n",
       "73300                          Anonymous   \n",
       "73301                          Anonymous   \n",
       "73302                          Anonymous   \n",
       "73303                          Anonymous   \n",
       "73304                          Anonymous   \n",
       "\n",
       "                                                metadata  \\\n",
       "0      {'acquisition': {'pixels_x': 640, 'pixels_y': ...   \n",
       "1      {'acquisition': {'pixels_x': 2448, 'pixels_y':...   \n",
       "2      {'acquisition': {'pixels_x': 640, 'pixels_y': ...   \n",
       "3      {'acquisition': {'pixels_x': 1409, 'pixels_y':...   \n",
       "4      {'acquisition': {'pixels_x': 498, 'pixels_y': ...   \n",
       "...                                                  ...   \n",
       "73300  {'acquisition': {'pixels_x': 1022, 'pixels_y':...   \n",
       "73301  {'acquisition': {'pixels_x': 1022, 'pixels_y':...   \n",
       "73302  {'acquisition': {'pixels_x': 1022, 'pixels_y':...   \n",
       "73303  {'acquisition': {'pixels_x': 1022, 'pixels_y':...   \n",
       "73304  {'acquisition': {'pixels_x': 1022, 'pixels_y':...   \n",
       "\n",
       "                                                   files  \n",
       "0      {'full': {'url': 'https://content.isic-archive...  \n",
       "1      {'full': {'url': 'https://content.isic-archive...  \n",
       "2      {'full': {'url': 'https://content.isic-archive...  \n",
       "3      {'full': {'url': 'https://content.isic-archive...  \n",
       "4      {'full': {'url': 'https://content.isic-archive...  \n",
       "...                                                  ...  \n",
       "73300  {'full': {'url': 'https://content.isic-archive...  \n",
       "73301  {'full': {'url': 'https://content.isic-archive...  \n",
       "73302  {'full': {'url': 'https://content.isic-archive...  \n",
       "73303  {'full': {'url': 'https://content.isic-archive...  \n",
       "73304  {'full': {'url': 'https://content.isic-archive...  \n",
       "\n",
       "[73305 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#API url\n",
    "url = \"https://api.isic-archive.com/api/v2/images/search/\"\n",
    "metadata_list = []\n",
    "\n",
    "while True:\n",
    "    response = requests.get(url)\n",
    "    response_data = response.json()\n",
    "    # Retrieve metadata from current page and add it to list\n",
    "    metadata_list.extend(response_data[\"results\"])\n",
    "    # Check if there are more pages\n",
    "    if response_data[\"next\"] != None:\n",
    "        url = response_data[\"next\"]\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Create dataframe from metadata list\n",
    "metadata_df = pd.DataFrame(metadata_list)\n",
    "\n",
    "# Print dataframe\n",
    "metadata_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17f9558",
   "metadata": {},
   "source": [
    "Extract the diagnosis information into it's own column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ebe9198-ed70-4eaf-8298-a3a133c45542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = list()\n",
    "for i in range(0, metadata_df.shape[0]):\n",
    "    if metadata_df.iloc[i]['metadata']['clinical'].get('diagnosis') is None:\n",
    "        l.append('NA')\n",
    "    else:\n",
    "        l.append(metadata_df.iloc[i]['metadata']['clinical']['diagnosis'])\n",
    "\n",
    "metadata_df['Diagnosis'] = l\n",
    "\n",
    "#metadata_df.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e98b3ee",
   "metadata": {},
   "source": [
    "Extract the image URL into it's own column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13ce0a48-fd06-4659-be68-13aa72a463e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = list()\n",
    "for i in range(0, metadata_df.shape[0]):\n",
    "    if metadata_df.iloc[i]['files']['thumbnail_256'].get('url') is None:\n",
    "        l.append('NA')\n",
    "    else:\n",
    "        l.append(metadata_df.iloc[i]['files']['thumbnail_256']['url'])\n",
    "\n",
    "metadata_df['URL'] = l\n",
    "\n",
    "#metadata_df.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b752725",
   "metadata": {},
   "source": [
    "Get the top 1000 melanoma images from the API and store in a directory called 'melanoma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2113ae2-f35c-4b09-b616-dbc8772ab517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if not os.path.exists(\"melanoma\"):\n",
    "    os.mkdir(\"melanoma\")\n",
    "\n",
    "\n",
    "metadata_df_mel_top = metadata_df[metadata_df['Diagnosis'] == 'melanoma']\n",
    "metadata_df_mel_top = metadata_df_mel_top.head(1000)\n",
    "\n",
    "for i in range(0, metadata_df_mel_top.shape[0]):\n",
    "    if metadata_df_mel_top.iloc[i]['URL'] != 'NA':\n",
    "        urllib.request.urlretrieve(metadata_df_mel_top.iloc[i]['URL'], metadata_df_mel_top.iloc[i]['isic_id'] + \".jpg\")\n",
    "        shutil.move(metadata_df_mel_top.iloc[i]['isic_id'] + \".jpg\", \"melanoma\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#urllib.request.urlretrieve(metadata_df.iloc[10003]['files']['full']['url'], \"image.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6f1d07",
   "metadata": {},
   "source": [
    "Get a random sample of 1000 non-melanoma images from the API and store in a directory called 'not melanoma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59e43119-42c7-4648-8015-d883fe285547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if not os.path.exists(\"not melanoma\"):\n",
    "    os.mkdir(\"not melanoma\")\n",
    "\n",
    "\n",
    "metadata_df_notmel_top = metadata_df[metadata_df['Diagnosis'] != 'melanoma']\n",
    "metadata_df_notmel_top = metadata_df_notmel_top[metadata_df_notmel_top['Diagnosis'] != 'NA']\n",
    "num_list = random.sample(range(0, metadata_df_notmel_top.shape[0]), 1000)\n",
    "\n",
    "for i in num_list:\n",
    "    if metadata_df_notmel_top.iloc[i]['URL'] != 'NA':\n",
    "        urllib.request.urlretrieve(metadata_df_notmel_top.iloc[i]['URL'], metadata_df_notmel_top.iloc[i]['isic_id'] + \".jpg\")\n",
    "        shutil.move(metadata_df_notmel_top.iloc[i]['isic_id'] + \".jpg\", \"not melanoma\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a256c",
   "metadata": {},
   "source": [
    "Re-organise the melanoma and non-melanoma images saved above into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afd275d8-eef0-46c8-a0d9-594aa1d5e863",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split datasets into train and test\n",
    "\n",
    "#create directorires for each of the dataset with separate folders for images that are melanoma and not melanoma\n",
    "if not os.path.exists(\"train\"):\n",
    "    os.mkdir(\"train\")\n",
    "    \n",
    "if not os.path.exists(\"test\"):\n",
    "    os.mkdir(\"test\")\n",
    "\n",
    "if not os.path.exists(\"train/melanoma\"):\n",
    "    os.mkdir(\"train/melanoma\")\n",
    "    \n",
    "if not os.path.exists(\"test/melanoma\"):\n",
    "    os.mkdir(\"test/melanoma\")\n",
    "    \n",
    "if not os.path.exists(\"train/not melanoma\"):\n",
    "    os.mkdir(\"train/not melanoma\")    \n",
    "    \n",
    "if not os.path.exists(\"test/not melanoma\"):\n",
    "    os.mkdir(\"test/not melanoma\")    \n",
    "\n",
    "    \n",
    "mel_list = list()\n",
    "\n",
    "    \n",
    "for p in os.listdir('melanoma'):\n",
    "    mel_list.append(p)  \n",
    "    \n",
    "random.shuffle(mel_list)\n",
    "train_data_mel, test_data_mel = train_test_split(mel_list,test_size=0.4) \n",
    "\n",
    "nmel_list = list()\n",
    "\n",
    "for p in os.listdir('not melanoma'):\n",
    "    nmel_list.append(p) \n",
    "    \n",
    "random.shuffle(nmel_list)\n",
    "train_data_nmel, test_data_nmel = train_test_split(nmel_list,test_size=0.4) \n",
    "\n",
    "for i in train_data_mel:\n",
    "    shutil.move(\"melanoma/\"+i, \"train/melanoma\")\n",
    "    \n",
    "for i in test_data_mel:\n",
    "    shutil.move(\"melanoma/\"+i, \"test/melanoma\")\n",
    "    \n",
    "for i in train_data_nmel:\n",
    "    shutil.move(\"not melanoma/\"+i, \"train/not melanoma\")\n",
    "    \n",
    "for i in test_data_nmel:\n",
    "    shutil.move(\"not melanoma/\"+i, \"test/not melanoma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d77494d",
   "metadata": {},
   "source": [
    "Create a function that can be used to create either the training or testing datasets by passing a file path, collecting each image under the file path, designating it as melanoma or not melanom, and converting each image to an RGB based numpy array that the neural network code can process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d6dcea-f17a-4bdb-8daf-5a9d2826c475",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['melanoma', 'not melanoma']\n",
    "img_size = 120\n",
    "\n",
    "def get_data(data_dir):\n",
    "    data = [] \n",
    "    for label in labels: \n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b113753d",
   "metadata": {},
   "source": [
    "Delete data from the following variables to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e424e8dd-1abb-4dad-a5ad-4cdf9ee84625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metadata_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b1794b9f061e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmetadata_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mmetadata_df_notmel_top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mmetadata_df_mel_top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mmel_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mnmel_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metadata_df' is not defined"
     ]
    }
   ],
   "source": [
    "del metadata_df\n",
    "del metadata_df_notmel_top\n",
    "del metadata_df_mel_top\n",
    "del mel_list\n",
    "del nmel_list\n",
    "del train_data_nmel\n",
    "del test_data_nmel\n",
    "del train_data_mel\n",
    "del test_data_mel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f387f3",
   "metadata": {},
   "source": [
    "Use the function defined above to create the training and testing datasets. Divide this into features and labels for each of the training and testing datasets. Following this, the data needs to be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3eff1b2-53e8-49e4-9cbf-e96c20f59f77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "train_data = get_data('train')\n",
    "\n",
    "for feature, label in train_data:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "del train_data\n",
    "\n",
    "test_data = get_data('test')\n",
    "\n",
    "for feature, label in test_data:\n",
    "    x_test.append(feature)\n",
    "    y_test.append(label)\n",
    "del test_data\n",
    "    \n",
    "# Normalize the data\n",
    "x_train = np.array(x_train) / 255\n",
    "x_test = np.array(x_test) / 255\n",
    "\n",
    "x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test.reshape(-1, img_size, img_size, 1)\n",
    "y_test = np.array(y_test)\n",
    "#Data augmentation on the train data:-\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1ae990",
   "metadata": {},
   "source": [
    "Create sequential convulutional neural network model with three hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17bf0655-30c0-4b61-8111-d53f6ddc27ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 120, 120, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 60, 60, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 60, 60, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 30, 30, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 15, 15, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 15, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1843328   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,872,226\n",
      "Trainable params: 1,872,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(img_size,img_size,3)))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = Adam(learning_rate=0.000001)\n",
    "model.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f27c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Train the CNN model defined above and observe the accuracy on the test and train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5491dfc3-578a-404e-ade1-61d3a4e3b2f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/backend.py:5586: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits, \"Softmax\", \"sparse_categorical_crossentropy\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 25s 653ms/step - loss: 0.6951 - accuracy: 0.5033 - val_loss: 0.6950 - val_accuracy: 0.5050\n",
      "Epoch 2/500\n",
      "38/38 [==============================] - 25s 653ms/step - loss: 0.6959 - accuracy: 0.4625 - val_loss: 0.6946 - val_accuracy: 0.5075\n",
      "Epoch 3/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.6948 - accuracy: 0.5100 - val_loss: 0.6942 - val_accuracy: 0.4787\n",
      "Epoch 4/500\n",
      "38/38 [==============================] - 25s 663ms/step - loss: 0.6954 - accuracy: 0.4858 - val_loss: 0.6938 - val_accuracy: 0.5038\n",
      "Epoch 5/500\n",
      "38/38 [==============================] - 24s 634ms/step - loss: 0.6942 - accuracy: 0.5158 - val_loss: 0.6935 - val_accuracy: 0.5412\n",
      "Epoch 6/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.6944 - accuracy: 0.4908 - val_loss: 0.6932 - val_accuracy: 0.5525\n",
      "Epoch 7/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.6932 - accuracy: 0.5200 - val_loss: 0.6929 - val_accuracy: 0.5612\n",
      "Epoch 8/500\n",
      "38/38 [==============================] - 24s 633ms/step - loss: 0.6936 - accuracy: 0.4883 - val_loss: 0.6926 - val_accuracy: 0.5612\n",
      "Epoch 9/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.6940 - accuracy: 0.5050 - val_loss: 0.6922 - val_accuracy: 0.5763\n",
      "Epoch 10/500\n",
      "38/38 [==============================] - 25s 654ms/step - loss: 0.6915 - accuracy: 0.5208 - val_loss: 0.6919 - val_accuracy: 0.5850\n",
      "Epoch 11/500\n",
      "38/38 [==============================] - 25s 656ms/step - loss: 0.6922 - accuracy: 0.5075 - val_loss: 0.6916 - val_accuracy: 0.5962\n",
      "Epoch 12/500\n",
      "38/38 [==============================] - 25s 649ms/step - loss: 0.6930 - accuracy: 0.5108 - val_loss: 0.6912 - val_accuracy: 0.6087\n",
      "Epoch 13/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.6912 - accuracy: 0.5208 - val_loss: 0.6909 - val_accuracy: 0.5825\n",
      "Epoch 14/500\n",
      "38/38 [==============================] - 25s 662ms/step - loss: 0.6918 - accuracy: 0.5142 - val_loss: 0.6906 - val_accuracy: 0.6012\n",
      "Epoch 15/500\n",
      "38/38 [==============================] - 25s 651ms/step - loss: 0.6900 - accuracy: 0.5450 - val_loss: 0.6903 - val_accuracy: 0.6100\n",
      "Epoch 16/500\n",
      "38/38 [==============================] - 25s 653ms/step - loss: 0.6931 - accuracy: 0.5150 - val_loss: 0.6900 - val_accuracy: 0.6212\n",
      "Epoch 17/500\n",
      "38/38 [==============================] - 25s 650ms/step - loss: 0.6896 - accuracy: 0.5308 - val_loss: 0.6896 - val_accuracy: 0.6012\n",
      "Epoch 18/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.6904 - accuracy: 0.5375 - val_loss: 0.6892 - val_accuracy: 0.6375\n",
      "Epoch 19/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.6904 - accuracy: 0.5342 - val_loss: 0.6889 - val_accuracy: 0.6350\n",
      "Epoch 20/500\n",
      "38/38 [==============================] - 25s 652ms/step - loss: 0.6895 - accuracy: 0.5383 - val_loss: 0.6885 - val_accuracy: 0.6438\n",
      "Epoch 21/500\n",
      "38/38 [==============================] - 25s 650ms/step - loss: 0.6908 - accuracy: 0.5308 - val_loss: 0.6882 - val_accuracy: 0.6375\n",
      "Epoch 22/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.6898 - accuracy: 0.5400 - val_loss: 0.6878 - val_accuracy: 0.6375\n",
      "Epoch 23/500\n",
      "38/38 [==============================] - 29s 781ms/step - loss: 0.6890 - accuracy: 0.5450 - val_loss: 0.6874 - val_accuracy: 0.6388\n",
      "Epoch 24/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6891 - accuracy: 0.5533 - val_loss: 0.6871 - val_accuracy: 0.6450\n",
      "Epoch 25/500\n",
      "38/38 [==============================] - 25s 652ms/step - loss: 0.6891 - accuracy: 0.5483 - val_loss: 0.6868 - val_accuracy: 0.6500\n",
      "Epoch 26/500\n",
      "38/38 [==============================] - 25s 659ms/step - loss: 0.6867 - accuracy: 0.5692 - val_loss: 0.6863 - val_accuracy: 0.6400\n",
      "Epoch 27/500\n",
      "38/38 [==============================] - 25s 654ms/step - loss: 0.6904 - accuracy: 0.5400 - val_loss: 0.6860 - val_accuracy: 0.6525\n",
      "Epoch 28/500\n",
      "38/38 [==============================] - 24s 647ms/step - loss: 0.6890 - accuracy: 0.5625 - val_loss: 0.6857 - val_accuracy: 0.6538\n",
      "Epoch 29/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6898 - accuracy: 0.5258 - val_loss: 0.6853 - val_accuracy: 0.6550\n",
      "Epoch 30/500\n",
      "38/38 [==============================] - 25s 652ms/step - loss: 0.6878 - accuracy: 0.5592 - val_loss: 0.6849 - val_accuracy: 0.6525\n",
      "Epoch 31/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6891 - accuracy: 0.5383 - val_loss: 0.6845 - val_accuracy: 0.6575\n",
      "Epoch 32/500\n",
      "38/38 [==============================] - 25s 652ms/step - loss: 0.6872 - accuracy: 0.5567 - val_loss: 0.6841 - val_accuracy: 0.6488\n",
      "Epoch 33/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.6883 - accuracy: 0.5517 - val_loss: 0.6838 - val_accuracy: 0.6562\n",
      "Epoch 34/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.6865 - accuracy: 0.5708 - val_loss: 0.6834 - val_accuracy: 0.6475\n",
      "Epoch 35/500\n",
      "38/38 [==============================] - 25s 671ms/step - loss: 0.6867 - accuracy: 0.5642 - val_loss: 0.6830 - val_accuracy: 0.6488\n",
      "Epoch 36/500\n",
      "38/38 [==============================] - 26s 681ms/step - loss: 0.6840 - accuracy: 0.5925 - val_loss: 0.6827 - val_accuracy: 0.6525\n",
      "Epoch 37/500\n",
      "38/38 [==============================] - 25s 657ms/step - loss: 0.6844 - accuracy: 0.5892 - val_loss: 0.6823 - val_accuracy: 0.6550\n",
      "Epoch 38/500\n",
      "38/38 [==============================] - 25s 656ms/step - loss: 0.6846 - accuracy: 0.5825 - val_loss: 0.6818 - val_accuracy: 0.6525\n",
      "Epoch 39/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.6829 - accuracy: 0.5892 - val_loss: 0.6814 - val_accuracy: 0.6525\n",
      "Epoch 40/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.6845 - accuracy: 0.5775 - val_loss: 0.6809 - val_accuracy: 0.6488\n",
      "Epoch 41/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.6845 - accuracy: 0.5783 - val_loss: 0.6805 - val_accuracy: 0.6500\n",
      "Epoch 42/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.6847 - accuracy: 0.5708 - val_loss: 0.6802 - val_accuracy: 0.6513\n",
      "Epoch 43/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.6819 - accuracy: 0.5950 - val_loss: 0.6798 - val_accuracy: 0.6463\n",
      "Epoch 44/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6828 - accuracy: 0.5942 - val_loss: 0.6793 - val_accuracy: 0.6500\n",
      "Epoch 45/500\n",
      "38/38 [==============================] - 25s 656ms/step - loss: 0.6837 - accuracy: 0.5683 - val_loss: 0.6789 - val_accuracy: 0.6500\n",
      "Epoch 46/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6815 - accuracy: 0.5833 - val_loss: 0.6785 - val_accuracy: 0.6525\n",
      "Epoch 47/500\n",
      "38/38 [==============================] - 24s 636ms/step - loss: 0.6820 - accuracy: 0.5783 - val_loss: 0.6781 - val_accuracy: 0.6525\n",
      "Epoch 48/500\n",
      "38/38 [==============================] - 25s 656ms/step - loss: 0.6827 - accuracy: 0.5750 - val_loss: 0.6777 - val_accuracy: 0.6500\n",
      "Epoch 49/500\n",
      "38/38 [==============================] - 24s 636ms/step - loss: 0.6813 - accuracy: 0.5983 - val_loss: 0.6774 - val_accuracy: 0.6488\n",
      "Epoch 50/500\n",
      "38/38 [==============================] - 25s 649ms/step - loss: 0.6805 - accuracy: 0.5892 - val_loss: 0.6769 - val_accuracy: 0.6513\n",
      "Epoch 51/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.6804 - accuracy: 0.5933 - val_loss: 0.6766 - val_accuracy: 0.6525\n",
      "Epoch 52/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6806 - accuracy: 0.5842 - val_loss: 0.6762 - val_accuracy: 0.6550\n",
      "Epoch 53/500\n",
      "38/38 [==============================] - 25s 639ms/step - loss: 0.6792 - accuracy: 0.5917 - val_loss: 0.6758 - val_accuracy: 0.6538\n",
      "Epoch 54/500\n",
      "38/38 [==============================] - 24s 636ms/step - loss: 0.6803 - accuracy: 0.5967 - val_loss: 0.6754 - val_accuracy: 0.6500\n",
      "Epoch 55/500\n",
      "38/38 [==============================] - 25s 666ms/step - loss: 0.6790 - accuracy: 0.6033 - val_loss: 0.6750 - val_accuracy: 0.6488\n",
      "Epoch 56/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.6778 - accuracy: 0.6000 - val_loss: 0.6746 - val_accuracy: 0.6475\n",
      "Epoch 57/500\n",
      "38/38 [==============================] - 25s 652ms/step - loss: 0.6777 - accuracy: 0.5967 - val_loss: 0.6742 - val_accuracy: 0.6488\n",
      "Epoch 58/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.6787 - accuracy: 0.6058 - val_loss: 0.6738 - val_accuracy: 0.6488\n",
      "Epoch 59/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.6794 - accuracy: 0.5992 - val_loss: 0.6735 - val_accuracy: 0.6475\n",
      "Epoch 60/500\n",
      "38/38 [==============================] - 25s 659ms/step - loss: 0.6771 - accuracy: 0.6125 - val_loss: 0.6731 - val_accuracy: 0.6500\n",
      "Epoch 61/500\n",
      "38/38 [==============================] - 24s 636ms/step - loss: 0.6783 - accuracy: 0.5992 - val_loss: 0.6727 - val_accuracy: 0.6450\n",
      "Epoch 62/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.6754 - accuracy: 0.6083 - val_loss: 0.6723 - val_accuracy: 0.6438\n",
      "Epoch 63/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6762 - accuracy: 0.6017 - val_loss: 0.6718 - val_accuracy: 0.6463\n",
      "Epoch 64/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.6782 - accuracy: 0.5967 - val_loss: 0.6714 - val_accuracy: 0.6450\n",
      "Epoch 65/500\n",
      "38/38 [==============================] - 25s 663ms/step - loss: 0.6771 - accuracy: 0.5950 - val_loss: 0.6710 - val_accuracy: 0.6438\n",
      "Epoch 66/500\n",
      "38/38 [==============================] - 24s 634ms/step - loss: 0.6752 - accuracy: 0.6033 - val_loss: 0.6706 - val_accuracy: 0.6425\n",
      "Epoch 67/500\n",
      "38/38 [==============================] - 25s 651ms/step - loss: 0.6748 - accuracy: 0.5975 - val_loss: 0.6701 - val_accuracy: 0.6438\n",
      "Epoch 68/500\n",
      "38/38 [==============================] - 24s 632ms/step - loss: 0.6728 - accuracy: 0.6200 - val_loss: 0.6697 - val_accuracy: 0.6450\n",
      "Epoch 69/500\n",
      "38/38 [==============================] - 24s 636ms/step - loss: 0.6741 - accuracy: 0.6000 - val_loss: 0.6692 - val_accuracy: 0.6438\n",
      "Epoch 70/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.6724 - accuracy: 0.5992 - val_loss: 0.6688 - val_accuracy: 0.6500\n",
      "Epoch 71/500\n",
      "38/38 [==============================] - 25s 652ms/step - loss: 0.6698 - accuracy: 0.6192 - val_loss: 0.6683 - val_accuracy: 0.6450\n",
      "Epoch 72/500\n",
      "38/38 [==============================] - 26s 676ms/step - loss: 0.6720 - accuracy: 0.6142 - val_loss: 0.6679 - val_accuracy: 0.6450\n",
      "Epoch 73/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.6731 - accuracy: 0.6125 - val_loss: 0.6674 - val_accuracy: 0.6450\n",
      "Epoch 74/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.6723 - accuracy: 0.6050 - val_loss: 0.6671 - val_accuracy: 0.6438\n",
      "Epoch 75/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.6731 - accuracy: 0.6008 - val_loss: 0.6666 - val_accuracy: 0.6438\n",
      "Epoch 76/500\n",
      "38/38 [==============================] - 25s 650ms/step - loss: 0.6712 - accuracy: 0.6117 - val_loss: 0.6662 - val_accuracy: 0.6475\n",
      "Epoch 77/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.6688 - accuracy: 0.6208 - val_loss: 0.6657 - val_accuracy: 0.6438\n",
      "Epoch 78/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.6705 - accuracy: 0.6200 - val_loss: 0.6653 - val_accuracy: 0.6488\n",
      "Epoch 79/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6689 - accuracy: 0.6150 - val_loss: 0.6649 - val_accuracy: 0.6450\n",
      "Epoch 80/500\n",
      "38/38 [==============================] - 24s 634ms/step - loss: 0.6680 - accuracy: 0.6258 - val_loss: 0.6645 - val_accuracy: 0.6475\n",
      "Epoch 81/500\n",
      "38/38 [==============================] - 24s 635ms/step - loss: 0.6685 - accuracy: 0.6208 - val_loss: 0.6640 - val_accuracy: 0.6500\n",
      "Epoch 82/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.6700 - accuracy: 0.6242 - val_loss: 0.6636 - val_accuracy: 0.6488\n",
      "Epoch 83/500\n",
      "38/38 [==============================] - 24s 636ms/step - loss: 0.6696 - accuracy: 0.6083 - val_loss: 0.6631 - val_accuracy: 0.6450\n",
      "Epoch 84/500\n",
      "38/38 [==============================] - 25s 650ms/step - loss: 0.6675 - accuracy: 0.6250 - val_loss: 0.6626 - val_accuracy: 0.6488\n",
      "Epoch 85/500\n",
      "38/38 [==============================] - 24s 633ms/step - loss: 0.6684 - accuracy: 0.6067 - val_loss: 0.6622 - val_accuracy: 0.6500\n",
      "Epoch 86/500\n",
      "38/38 [==============================] - 24s 632ms/step - loss: 0.6657 - accuracy: 0.6250 - val_loss: 0.6617 - val_accuracy: 0.6500\n",
      "Epoch 87/500\n",
      "38/38 [==============================] - 25s 662ms/step - loss: 0.6649 - accuracy: 0.6258 - val_loss: 0.6613 - val_accuracy: 0.6450\n",
      "Epoch 88/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6667 - accuracy: 0.6233 - val_loss: 0.6608 - val_accuracy: 0.6463\n",
      "Epoch 89/500\n",
      "38/38 [==============================] - 25s 649ms/step - loss: 0.6667 - accuracy: 0.6258 - val_loss: 0.6604 - val_accuracy: 0.6450\n",
      "Epoch 90/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6660 - accuracy: 0.6292 - val_loss: 0.6600 - val_accuracy: 0.6525\n",
      "Epoch 91/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.6653 - accuracy: 0.6233 - val_loss: 0.6596 - val_accuracy: 0.6463\n",
      "Epoch 92/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.6635 - accuracy: 0.6317 - val_loss: 0.6591 - val_accuracy: 0.6438\n",
      "Epoch 93/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6636 - accuracy: 0.6375 - val_loss: 0.6587 - val_accuracy: 0.6500\n",
      "Epoch 94/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.6645 - accuracy: 0.6342 - val_loss: 0.6581 - val_accuracy: 0.6450\n",
      "Epoch 95/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6654 - accuracy: 0.6167 - val_loss: 0.6578 - val_accuracy: 0.6550\n",
      "Epoch 96/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.6650 - accuracy: 0.6375 - val_loss: 0.6574 - val_accuracy: 0.6587\n",
      "Epoch 97/500\n",
      "38/38 [==============================] - 26s 681ms/step - loss: 0.6649 - accuracy: 0.6250 - val_loss: 0.6568 - val_accuracy: 0.6538\n",
      "Epoch 98/500\n",
      "38/38 [==============================] - 24s 635ms/step - loss: 0.6622 - accuracy: 0.6383 - val_loss: 0.6564 - val_accuracy: 0.6538\n",
      "Epoch 99/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.6623 - accuracy: 0.6300 - val_loss: 0.6559 - val_accuracy: 0.6500\n",
      "Epoch 100/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6621 - accuracy: 0.6325 - val_loss: 0.6555 - val_accuracy: 0.6538\n",
      "Epoch 101/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6568 - accuracy: 0.6492 - val_loss: 0.6550 - val_accuracy: 0.6538\n",
      "Epoch 102/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.6606 - accuracy: 0.6317 - val_loss: 0.6545 - val_accuracy: 0.6525\n",
      "Epoch 103/500\n",
      "38/38 [==============================] - 24s 635ms/step - loss: 0.6590 - accuracy: 0.6517 - val_loss: 0.6541 - val_accuracy: 0.6525\n",
      "Epoch 104/500\n",
      "38/38 [==============================] - 24s 634ms/step - loss: 0.6595 - accuracy: 0.6392 - val_loss: 0.6536 - val_accuracy: 0.6538\n",
      "Epoch 105/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6583 - accuracy: 0.6400 - val_loss: 0.6531 - val_accuracy: 0.6562\n",
      "Epoch 106/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.6593 - accuracy: 0.6408 - val_loss: 0.6527 - val_accuracy: 0.6562\n",
      "Epoch 107/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.6550 - accuracy: 0.6667 - val_loss: 0.6523 - val_accuracy: 0.6562\n",
      "Epoch 108/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.6569 - accuracy: 0.6500 - val_loss: 0.6518 - val_accuracy: 0.6575\n",
      "Epoch 109/500\n",
      "38/38 [==============================] - 25s 658ms/step - loss: 0.6564 - accuracy: 0.6575 - val_loss: 0.6513 - val_accuracy: 0.6575\n",
      "Epoch 110/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.6546 - accuracy: 0.6608 - val_loss: 0.6509 - val_accuracy: 0.6612\n",
      "Epoch 111/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.6578 - accuracy: 0.6433 - val_loss: 0.6505 - val_accuracy: 0.6637\n",
      "Epoch 112/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.6555 - accuracy: 0.6358 - val_loss: 0.6500 - val_accuracy: 0.6600\n",
      "Epoch 113/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6537 - accuracy: 0.6567 - val_loss: 0.6496 - val_accuracy: 0.6612\n",
      "Epoch 114/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.6539 - accuracy: 0.6492 - val_loss: 0.6492 - val_accuracy: 0.6662\n",
      "Epoch 115/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.6530 - accuracy: 0.6467 - val_loss: 0.6487 - val_accuracy: 0.6650\n",
      "Epoch 116/500\n",
      "38/38 [==============================] - 25s 652ms/step - loss: 0.6520 - accuracy: 0.6675 - val_loss: 0.6483 - val_accuracy: 0.6650\n",
      "Epoch 117/500\n",
      "38/38 [==============================] - 25s 647ms/step - loss: 0.6513 - accuracy: 0.6600 - val_loss: 0.6478 - val_accuracy: 0.6662\n",
      "Epoch 118/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.6523 - accuracy: 0.6383 - val_loss: 0.6474 - val_accuracy: 0.6662\n",
      "Epoch 119/500\n",
      "38/38 [==============================] - 25s 663ms/step - loss: 0.6551 - accuracy: 0.6592 - val_loss: 0.6470 - val_accuracy: 0.6712\n",
      "Epoch 120/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.6518 - accuracy: 0.6567 - val_loss: 0.6465 - val_accuracy: 0.6687\n",
      "Epoch 121/500\n",
      "38/38 [==============================] - 25s 662ms/step - loss: 0.6538 - accuracy: 0.6392 - val_loss: 0.6462 - val_accuracy: 0.6700\n",
      "Epoch 122/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.6508 - accuracy: 0.6583 - val_loss: 0.6457 - val_accuracy: 0.6750\n",
      "Epoch 123/500\n",
      "38/38 [==============================] - 25s 656ms/step - loss: 0.6505 - accuracy: 0.6558 - val_loss: 0.6452 - val_accuracy: 0.6750\n",
      "Epoch 124/500\n",
      "38/38 [==============================] - 25s 661ms/step - loss: 0.6499 - accuracy: 0.6742 - val_loss: 0.6448 - val_accuracy: 0.6775\n",
      "Epoch 125/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6530 - accuracy: 0.6467 - val_loss: 0.6444 - val_accuracy: 0.6737\n",
      "Epoch 126/500\n",
      "38/38 [==============================] - 26s 675ms/step - loss: 0.6494 - accuracy: 0.6708 - val_loss: 0.6440 - val_accuracy: 0.6775\n",
      "Epoch 127/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6478 - accuracy: 0.6767 - val_loss: 0.6435 - val_accuracy: 0.6750\n",
      "Epoch 128/500\n",
      "38/38 [==============================] - 25s 658ms/step - loss: 0.6454 - accuracy: 0.6750 - val_loss: 0.6431 - val_accuracy: 0.6850\n",
      "Epoch 129/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.6491 - accuracy: 0.6717 - val_loss: 0.6426 - val_accuracy: 0.6750\n",
      "Epoch 130/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.6457 - accuracy: 0.6633 - val_loss: 0.6422 - val_accuracy: 0.6812\n",
      "Epoch 131/500\n",
      "38/38 [==============================] - 25s 665ms/step - loss: 0.6485 - accuracy: 0.6633 - val_loss: 0.6418 - val_accuracy: 0.6825\n",
      "Epoch 132/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.6472 - accuracy: 0.6700 - val_loss: 0.6414 - val_accuracy: 0.6775\n",
      "Epoch 133/500\n",
      "38/38 [==============================] - 26s 680ms/step - loss: 0.6453 - accuracy: 0.6667 - val_loss: 0.6410 - val_accuracy: 0.6862\n",
      "Epoch 134/500\n",
      "38/38 [==============================] - 25s 643ms/step - loss: 0.6494 - accuracy: 0.6508 - val_loss: 0.6406 - val_accuracy: 0.6825\n",
      "Epoch 135/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.6484 - accuracy: 0.6550 - val_loss: 0.6402 - val_accuracy: 0.6812\n",
      "Epoch 136/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.6447 - accuracy: 0.6700 - val_loss: 0.6397 - val_accuracy: 0.6862\n",
      "Epoch 137/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.6460 - accuracy: 0.6625 - val_loss: 0.6394 - val_accuracy: 0.6812\n",
      "Epoch 138/500\n",
      "38/38 [==============================] - 24s 647ms/step - loss: 0.6448 - accuracy: 0.6708 - val_loss: 0.6390 - val_accuracy: 0.6825\n",
      "Epoch 139/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.6448 - accuracy: 0.6750 - val_loss: 0.6385 - val_accuracy: 0.6837\n",
      "Epoch 140/500\n",
      "38/38 [==============================] - 24s 647ms/step - loss: 0.6438 - accuracy: 0.6575 - val_loss: 0.6382 - val_accuracy: 0.6825\n",
      "Epoch 141/500\n",
      "38/38 [==============================] - 25s 660ms/step - loss: 0.6441 - accuracy: 0.6733 - val_loss: 0.6377 - val_accuracy: 0.6850\n",
      "Epoch 142/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.6410 - accuracy: 0.6858 - val_loss: 0.6373 - val_accuracy: 0.6837\n",
      "Epoch 143/500\n",
      "38/38 [==============================] - 25s 651ms/step - loss: 0.6417 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6850\n",
      "Epoch 144/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.6417 - accuracy: 0.6725 - val_loss: 0.6365 - val_accuracy: 0.6837\n",
      "Epoch 145/500\n",
      "38/38 [==============================] - 24s 647ms/step - loss: 0.6444 - accuracy: 0.6667 - val_loss: 0.6361 - val_accuracy: 0.6825\n",
      "Epoch 146/500\n",
      "38/38 [==============================] - 25s 672ms/step - loss: 0.6413 - accuracy: 0.6742 - val_loss: 0.6357 - val_accuracy: 0.6837\n",
      "Epoch 147/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6388 - accuracy: 0.6808 - val_loss: 0.6353 - val_accuracy: 0.6862\n",
      "Epoch 148/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.6421 - accuracy: 0.6658 - val_loss: 0.6349 - val_accuracy: 0.6837\n",
      "Epoch 149/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.6392 - accuracy: 0.6817 - val_loss: 0.6345 - val_accuracy: 0.6850\n",
      "Epoch 150/500\n",
      "38/38 [==============================] - 26s 679ms/step - loss: 0.6392 - accuracy: 0.6717 - val_loss: 0.6341 - val_accuracy: 0.6913\n",
      "Epoch 151/500\n",
      "38/38 [==============================] - 25s 653ms/step - loss: 0.6367 - accuracy: 0.6917 - val_loss: 0.6337 - val_accuracy: 0.6862\n",
      "Epoch 152/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.6381 - accuracy: 0.6725 - val_loss: 0.6333 - val_accuracy: 0.6888\n",
      "Epoch 153/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.6340 - accuracy: 0.6867 - val_loss: 0.6329 - val_accuracy: 0.6837\n",
      "Epoch 154/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.6379 - accuracy: 0.6733 - val_loss: 0.6325 - val_accuracy: 0.6900\n",
      "Epoch 155/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.6365 - accuracy: 0.6808 - val_loss: 0.6321 - val_accuracy: 0.6888\n",
      "Epoch 156/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.6356 - accuracy: 0.6883 - val_loss: 0.6317 - val_accuracy: 0.6925\n",
      "Epoch 157/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6351 - accuracy: 0.6858 - val_loss: 0.6313 - val_accuracy: 0.6900\n",
      "Epoch 158/500\n",
      "38/38 [==============================] - 25s 673ms/step - loss: 0.6353 - accuracy: 0.6825 - val_loss: 0.6309 - val_accuracy: 0.6888\n",
      "Epoch 159/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.6350 - accuracy: 0.6825 - val_loss: 0.6305 - val_accuracy: 0.6938\n",
      "Epoch 160/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.6350 - accuracy: 0.6750 - val_loss: 0.6301 - val_accuracy: 0.6900\n",
      "Epoch 161/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.6339 - accuracy: 0.6817 - val_loss: 0.6297 - val_accuracy: 0.6925\n",
      "Epoch 162/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.6372 - accuracy: 0.6758 - val_loss: 0.6293 - val_accuracy: 0.6900\n",
      "Epoch 163/500\n",
      "38/38 [==============================] - 25s 653ms/step - loss: 0.6344 - accuracy: 0.6833 - val_loss: 0.6289 - val_accuracy: 0.6925\n",
      "Epoch 164/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.6351 - accuracy: 0.6733 - val_loss: 0.6285 - val_accuracy: 0.6888\n",
      "Epoch 165/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.6347 - accuracy: 0.6733 - val_loss: 0.6281 - val_accuracy: 0.6950\n",
      "Epoch 166/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6324 - accuracy: 0.6850 - val_loss: 0.6277 - val_accuracy: 0.6925\n",
      "Epoch 167/500\n",
      "38/38 [==============================] - 26s 681ms/step - loss: 0.6284 - accuracy: 0.6850 - val_loss: 0.6274 - val_accuracy: 0.6913\n",
      "Epoch 168/500\n",
      "38/38 [==============================] - 25s 644ms/step - loss: 0.6319 - accuracy: 0.6950 - val_loss: 0.6269 - val_accuracy: 0.6925\n",
      "Epoch 169/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6332 - accuracy: 0.6883 - val_loss: 0.6266 - val_accuracy: 0.6925\n",
      "Epoch 170/500\n",
      "38/38 [==============================] - 29s 776ms/step - loss: 0.6311 - accuracy: 0.6642 - val_loss: 0.6262 - val_accuracy: 0.6988\n",
      "Epoch 171/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.6304 - accuracy: 0.6892 - val_loss: 0.6258 - val_accuracy: 0.6963\n",
      "Epoch 172/500\n",
      "38/38 [==============================] - 26s 698ms/step - loss: 0.6292 - accuracy: 0.6908 - val_loss: 0.6254 - val_accuracy: 0.6900\n",
      "Epoch 173/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.6272 - accuracy: 0.6950 - val_loss: 0.6251 - val_accuracy: 0.6913\n",
      "Epoch 174/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.6294 - accuracy: 0.6867 - val_loss: 0.6246 - val_accuracy: 0.6963\n",
      "Epoch 175/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.6313 - accuracy: 0.6717 - val_loss: 0.6243 - val_accuracy: 0.6988\n",
      "Epoch 176/500\n",
      "38/38 [==============================] - 24s 636ms/step - loss: 0.6302 - accuracy: 0.6842 - val_loss: 0.6239 - val_accuracy: 0.6988\n",
      "Epoch 177/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.6278 - accuracy: 0.7017 - val_loss: 0.6235 - val_accuracy: 0.6975\n",
      "Epoch 178/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.6279 - accuracy: 0.6742 - val_loss: 0.6231 - val_accuracy: 0.6988\n",
      "Epoch 179/500\n",
      "38/38 [==============================] - 24s 636ms/step - loss: 0.6259 - accuracy: 0.6992 - val_loss: 0.6228 - val_accuracy: 0.6888\n",
      "Epoch 180/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.6259 - accuracy: 0.6883 - val_loss: 0.6223 - val_accuracy: 0.6988\n",
      "Epoch 181/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.6258 - accuracy: 0.6992 - val_loss: 0.6219 - val_accuracy: 0.6963\n",
      "Epoch 182/500\n",
      "38/38 [==============================] - 24s 647ms/step - loss: 0.6246 - accuracy: 0.6867 - val_loss: 0.6215 - val_accuracy: 0.7000\n",
      "Epoch 183/500\n",
      "38/38 [==============================] - 24s 636ms/step - loss: 0.6265 - accuracy: 0.7017 - val_loss: 0.6211 - val_accuracy: 0.7013\n",
      "Epoch 184/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.6241 - accuracy: 0.6917 - val_loss: 0.6208 - val_accuracy: 0.6913\n",
      "Epoch 185/500\n",
      "38/38 [==============================] - 26s 688ms/step - loss: 0.6244 - accuracy: 0.7017 - val_loss: 0.6204 - val_accuracy: 0.7013\n",
      "Epoch 186/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6268 - accuracy: 0.6867 - val_loss: 0.6200 - val_accuracy: 0.6938\n",
      "Epoch 187/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.6218 - accuracy: 0.7008 - val_loss: 0.6196 - val_accuracy: 0.7025\n",
      "Epoch 188/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.6229 - accuracy: 0.6900 - val_loss: 0.6193 - val_accuracy: 0.6913\n",
      "Epoch 189/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6223 - accuracy: 0.7025 - val_loss: 0.6188 - val_accuracy: 0.7063\n",
      "Epoch 190/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6233 - accuracy: 0.6858 - val_loss: 0.6184 - val_accuracy: 0.6975\n",
      "Epoch 191/500\n",
      "38/38 [==============================] - 25s 649ms/step - loss: 0.6231 - accuracy: 0.6883 - val_loss: 0.6180 - val_accuracy: 0.6988\n",
      "Epoch 192/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6223 - accuracy: 0.7058 - val_loss: 0.6177 - val_accuracy: 0.7063\n",
      "Epoch 193/500\n",
      "38/38 [==============================] - 24s 635ms/step - loss: 0.6207 - accuracy: 0.6975 - val_loss: 0.6173 - val_accuracy: 0.7000\n",
      "Epoch 194/500\n",
      "38/38 [==============================] - 25s 652ms/step - loss: 0.6186 - accuracy: 0.6992 - val_loss: 0.6169 - val_accuracy: 0.7063\n",
      "Epoch 195/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6211 - accuracy: 0.6942 - val_loss: 0.6165 - val_accuracy: 0.7013\n",
      "Epoch 196/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6217 - accuracy: 0.6917 - val_loss: 0.6161 - val_accuracy: 0.7088\n",
      "Epoch 197/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.6192 - accuracy: 0.7067 - val_loss: 0.6157 - val_accuracy: 0.7038\n",
      "Epoch 198/500\n",
      "38/38 [==============================] - 24s 634ms/step - loss: 0.6207 - accuracy: 0.7000 - val_loss: 0.6153 - val_accuracy: 0.7050\n",
      "Epoch 199/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.6178 - accuracy: 0.6983 - val_loss: 0.6149 - val_accuracy: 0.7063\n",
      "Epoch 200/500\n",
      "38/38 [==============================] - 24s 636ms/step - loss: 0.6178 - accuracy: 0.6867 - val_loss: 0.6145 - val_accuracy: 0.7025\n",
      "Epoch 201/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.6163 - accuracy: 0.7025 - val_loss: 0.6141 - val_accuracy: 0.7063\n",
      "Epoch 202/500\n",
      "38/38 [==============================] - 25s 649ms/step - loss: 0.6185 - accuracy: 0.6983 - val_loss: 0.6137 - val_accuracy: 0.7063\n",
      "Epoch 203/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6173 - accuracy: 0.7025 - val_loss: 0.6133 - val_accuracy: 0.7038\n",
      "Epoch 204/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.6170 - accuracy: 0.6992 - val_loss: 0.6129 - val_accuracy: 0.7088\n",
      "Epoch 205/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.6173 - accuracy: 0.6975 - val_loss: 0.6125 - val_accuracy: 0.7063\n",
      "Epoch 206/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6150 - accuracy: 0.6917 - val_loss: 0.6120 - val_accuracy: 0.7050\n",
      "Epoch 207/500\n",
      "38/38 [==============================] - 25s 666ms/step - loss: 0.6131 - accuracy: 0.7000 - val_loss: 0.6116 - val_accuracy: 0.7063\n",
      "Epoch 208/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.6163 - accuracy: 0.7067 - val_loss: 0.6112 - val_accuracy: 0.7100\n",
      "Epoch 209/500\n",
      "38/38 [==============================] - 25s 651ms/step - loss: 0.6148 - accuracy: 0.6950 - val_loss: 0.6107 - val_accuracy: 0.7125\n",
      "Epoch 210/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.6125 - accuracy: 0.7000 - val_loss: 0.6103 - val_accuracy: 0.7113\n",
      "Epoch 211/500\n",
      "38/38 [==============================] - 24s 647ms/step - loss: 0.6133 - accuracy: 0.6925 - val_loss: 0.6099 - val_accuracy: 0.7113\n",
      "Epoch 212/500\n",
      "38/38 [==============================] - 25s 662ms/step - loss: 0.6107 - accuracy: 0.7017 - val_loss: 0.6095 - val_accuracy: 0.7088\n",
      "Epoch 213/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.6116 - accuracy: 0.6967 - val_loss: 0.6091 - val_accuracy: 0.7125\n",
      "Epoch 214/500\n",
      "38/38 [==============================] - 25s 651ms/step - loss: 0.6114 - accuracy: 0.7133 - val_loss: 0.6086 - val_accuracy: 0.7138\n",
      "Epoch 215/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.6126 - accuracy: 0.7142 - val_loss: 0.6082 - val_accuracy: 0.7150\n",
      "Epoch 216/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.6124 - accuracy: 0.7033 - val_loss: 0.6079 - val_accuracy: 0.7138\n",
      "Epoch 217/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.6108 - accuracy: 0.7017 - val_loss: 0.6075 - val_accuracy: 0.7150\n",
      "Epoch 218/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6077 - accuracy: 0.7083 - val_loss: 0.6071 - val_accuracy: 0.7150\n",
      "Epoch 219/500\n",
      "38/38 [==============================] - 25s 654ms/step - loss: 0.6096 - accuracy: 0.7075 - val_loss: 0.6067 - val_accuracy: 0.7138\n",
      "Epoch 220/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6080 - accuracy: 0.7150 - val_loss: 0.6063 - val_accuracy: 0.7163\n",
      "Epoch 221/500\n",
      "38/38 [==============================] - 25s 656ms/step - loss: 0.6094 - accuracy: 0.7142 - val_loss: 0.6059 - val_accuracy: 0.7163\n",
      "Epoch 222/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.6097 - accuracy: 0.7058 - val_loss: 0.6055 - val_accuracy: 0.7150\n",
      "Epoch 223/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6070 - accuracy: 0.7108 - val_loss: 0.6051 - val_accuracy: 0.7163\n",
      "Epoch 224/500\n",
      "38/38 [==============================] - 24s 636ms/step - loss: 0.6086 - accuracy: 0.7067 - val_loss: 0.6048 - val_accuracy: 0.7163\n",
      "Epoch 225/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.6056 - accuracy: 0.7183 - val_loss: 0.6044 - val_accuracy: 0.7163\n",
      "Epoch 226/500\n",
      "38/38 [==============================] - 25s 656ms/step - loss: 0.6042 - accuracy: 0.7142 - val_loss: 0.6041 - val_accuracy: 0.7150\n",
      "Epoch 227/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.6072 - accuracy: 0.7058 - val_loss: 0.6037 - val_accuracy: 0.7150\n",
      "Epoch 228/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.6047 - accuracy: 0.7075 - val_loss: 0.6034 - val_accuracy: 0.7138\n",
      "Epoch 229/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.6076 - accuracy: 0.7150 - val_loss: 0.6030 - val_accuracy: 0.7163\n",
      "Epoch 230/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.6068 - accuracy: 0.7042 - val_loss: 0.6027 - val_accuracy: 0.7113\n",
      "Epoch 231/500\n",
      "38/38 [==============================] - 25s 651ms/step - loss: 0.6048 - accuracy: 0.7050 - val_loss: 0.6022 - val_accuracy: 0.7163\n",
      "Epoch 232/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.6023 - accuracy: 0.7050 - val_loss: 0.6019 - val_accuracy: 0.7138\n",
      "Epoch 233/500\n",
      "38/38 [==============================] - 24s 636ms/step - loss: 0.6031 - accuracy: 0.7292 - val_loss: 0.6015 - val_accuracy: 0.7138\n",
      "Epoch 234/500\n",
      "38/38 [==============================] - 25s 656ms/step - loss: 0.6018 - accuracy: 0.7108 - val_loss: 0.6011 - val_accuracy: 0.7150\n",
      "Epoch 235/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6044 - accuracy: 0.7125 - val_loss: 0.6007 - val_accuracy: 0.7163\n",
      "Epoch 236/500\n",
      "38/38 [==============================] - 25s 651ms/step - loss: 0.6027 - accuracy: 0.7117 - val_loss: 0.6004 - val_accuracy: 0.7175\n",
      "Epoch 237/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.6002 - accuracy: 0.7158 - val_loss: 0.6000 - val_accuracy: 0.7150\n",
      "Epoch 238/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.6005 - accuracy: 0.7117 - val_loss: 0.5997 - val_accuracy: 0.7163\n",
      "Epoch 239/500\n",
      "38/38 [==============================] - 25s 649ms/step - loss: 0.6016 - accuracy: 0.7133 - val_loss: 0.5993 - val_accuracy: 0.7163\n",
      "Epoch 240/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.6020 - accuracy: 0.6975 - val_loss: 0.5990 - val_accuracy: 0.7175\n",
      "Epoch 241/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.6015 - accuracy: 0.6983 - val_loss: 0.5986 - val_accuracy: 0.7150\n",
      "Epoch 242/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.5988 - accuracy: 0.7108 - val_loss: 0.5982 - val_accuracy: 0.7163\n",
      "Epoch 243/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.5969 - accuracy: 0.7150 - val_loss: 0.5980 - val_accuracy: 0.7138\n",
      "Epoch 244/500\n",
      "38/38 [==============================] - 26s 685ms/step - loss: 0.5998 - accuracy: 0.7133 - val_loss: 0.5976 - val_accuracy: 0.7150\n",
      "Epoch 245/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.5999 - accuracy: 0.7267 - val_loss: 0.5972 - val_accuracy: 0.7163\n",
      "Epoch 246/500\n",
      "38/38 [==============================] - 25s 654ms/step - loss: 0.5998 - accuracy: 0.7150 - val_loss: 0.5969 - val_accuracy: 0.7188\n",
      "Epoch 247/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.5999 - accuracy: 0.7233 - val_loss: 0.5966 - val_accuracy: 0.7138\n",
      "Epoch 248/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.5969 - accuracy: 0.7017 - val_loss: 0.5962 - val_accuracy: 0.7163\n",
      "Epoch 249/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.5943 - accuracy: 0.7233 - val_loss: 0.5959 - val_accuracy: 0.7138\n",
      "Epoch 250/500\n",
      "38/38 [==============================] - 25s 649ms/step - loss: 0.5967 - accuracy: 0.7133 - val_loss: 0.5955 - val_accuracy: 0.7175\n",
      "Epoch 251/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.5957 - accuracy: 0.7117 - val_loss: 0.5952 - val_accuracy: 0.7100\n",
      "Epoch 252/500\n",
      "38/38 [==============================] - 25s 657ms/step - loss: 0.5950 - accuracy: 0.7192 - val_loss: 0.5948 - val_accuracy: 0.7200\n",
      "Epoch 253/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.5946 - accuracy: 0.7200 - val_loss: 0.5944 - val_accuracy: 0.7175\n",
      "Epoch 254/500\n",
      "38/38 [==============================] - 25s 654ms/step - loss: 0.5947 - accuracy: 0.7050 - val_loss: 0.5942 - val_accuracy: 0.7125\n",
      "Epoch 255/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.5927 - accuracy: 0.7117 - val_loss: 0.5938 - val_accuracy: 0.7125\n",
      "Epoch 256/500\n",
      "38/38 [==============================] - 25s 663ms/step - loss: 0.5939 - accuracy: 0.7267 - val_loss: 0.5934 - val_accuracy: 0.7188\n",
      "Epoch 257/500\n",
      "38/38 [==============================] - 25s 658ms/step - loss: 0.5912 - accuracy: 0.7133 - val_loss: 0.5930 - val_accuracy: 0.7188\n",
      "Epoch 258/500\n",
      "38/38 [==============================] - 25s 663ms/step - loss: 0.5921 - accuracy: 0.7258 - val_loss: 0.5927 - val_accuracy: 0.7150\n",
      "Epoch 259/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.5942 - accuracy: 0.7267 - val_loss: 0.5924 - val_accuracy: 0.7163\n",
      "Epoch 260/500\n",
      "38/38 [==============================] - 25s 657ms/step - loss: 0.5934 - accuracy: 0.7092 - val_loss: 0.5920 - val_accuracy: 0.7200\n",
      "Epoch 261/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.5925 - accuracy: 0.7250 - val_loss: 0.5916 - val_accuracy: 0.7175\n",
      "Epoch 262/500\n",
      "38/38 [==============================] - 25s 656ms/step - loss: 0.5944 - accuracy: 0.7092 - val_loss: 0.5913 - val_accuracy: 0.7225\n",
      "Epoch 263/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.5932 - accuracy: 0.7058 - val_loss: 0.5910 - val_accuracy: 0.7175\n",
      "Epoch 264/500\n",
      "38/38 [==============================] - 25s 657ms/step - loss: 0.5903 - accuracy: 0.7175 - val_loss: 0.5907 - val_accuracy: 0.7188\n",
      "Epoch 265/500\n",
      "38/38 [==============================] - 25s 659ms/step - loss: 0.5908 - accuracy: 0.7175 - val_loss: 0.5903 - val_accuracy: 0.7225\n",
      "Epoch 266/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.5910 - accuracy: 0.7083 - val_loss: 0.5900 - val_accuracy: 0.7175\n",
      "Epoch 267/500\n",
      "38/38 [==============================] - 25s 660ms/step - loss: 0.5855 - accuracy: 0.7267 - val_loss: 0.5897 - val_accuracy: 0.7188\n",
      "Epoch 268/500\n",
      "38/38 [==============================] - 27s 708ms/step - loss: 0.5896 - accuracy: 0.7100 - val_loss: 0.5894 - val_accuracy: 0.7138\n",
      "Epoch 269/500\n",
      "38/38 [==============================] - 25s 657ms/step - loss: 0.5882 - accuracy: 0.7233 - val_loss: 0.5890 - val_accuracy: 0.7175\n",
      "Epoch 270/500\n",
      "38/38 [==============================] - 25s 664ms/step - loss: 0.5876 - accuracy: 0.7167 - val_loss: 0.5887 - val_accuracy: 0.7138\n",
      "Epoch 271/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.5892 - accuracy: 0.7108 - val_loss: 0.5883 - val_accuracy: 0.7175\n",
      "Epoch 272/500\n",
      "38/38 [==============================] - 26s 686ms/step - loss: 0.5866 - accuracy: 0.7200 - val_loss: 0.5880 - val_accuracy: 0.7163\n",
      "Epoch 273/500\n",
      "38/38 [==============================] - 25s 654ms/step - loss: 0.5883 - accuracy: 0.7183 - val_loss: 0.5876 - val_accuracy: 0.7200\n",
      "Epoch 274/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.5876 - accuracy: 0.7225 - val_loss: 0.5872 - val_accuracy: 0.7188\n",
      "Epoch 275/500\n",
      "38/38 [==============================] - 24s 647ms/step - loss: 0.5877 - accuracy: 0.7300 - val_loss: 0.5869 - val_accuracy: 0.7188\n",
      "Epoch 276/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.5871 - accuracy: 0.7250 - val_loss: 0.5866 - val_accuracy: 0.7188\n",
      "Epoch 277/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.5860 - accuracy: 0.7233 - val_loss: 0.5863 - val_accuracy: 0.7150\n",
      "Epoch 278/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.5880 - accuracy: 0.7208 - val_loss: 0.5860 - val_accuracy: 0.7250\n",
      "Epoch 279/500\n",
      "38/38 [==============================] - 25s 659ms/step - loss: 0.5839 - accuracy: 0.7208 - val_loss: 0.5859 - val_accuracy: 0.7100\n",
      "Epoch 280/500\n",
      "38/38 [==============================] - 25s 662ms/step - loss: 0.5850 - accuracy: 0.7267 - val_loss: 0.5854 - val_accuracy: 0.7237\n",
      "Epoch 281/500\n",
      "38/38 [==============================] - 25s 649ms/step - loss: 0.5848 - accuracy: 0.7175 - val_loss: 0.5851 - val_accuracy: 0.7200\n",
      "Epoch 282/500\n",
      "38/38 [==============================] - 25s 670ms/step - loss: 0.5836 - accuracy: 0.7283 - val_loss: 0.5847 - val_accuracy: 0.7275\n",
      "Epoch 283/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.5826 - accuracy: 0.7375 - val_loss: 0.5843 - val_accuracy: 0.7212\n",
      "Epoch 284/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.5823 - accuracy: 0.7242 - val_loss: 0.5841 - val_accuracy: 0.7262\n",
      "Epoch 285/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.5827 - accuracy: 0.7208 - val_loss: 0.5838 - val_accuracy: 0.7275\n",
      "Epoch 286/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.5838 - accuracy: 0.7175 - val_loss: 0.5834 - val_accuracy: 0.7287\n",
      "Epoch 287/500\n",
      "38/38 [==============================] - 25s 650ms/step - loss: 0.5831 - accuracy: 0.7200 - val_loss: 0.5831 - val_accuracy: 0.7250\n",
      "Epoch 288/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.5817 - accuracy: 0.7208 - val_loss: 0.5828 - val_accuracy: 0.7250\n",
      "Epoch 289/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.5814 - accuracy: 0.7375 - val_loss: 0.5825 - val_accuracy: 0.7237\n",
      "Epoch 290/500\n",
      "38/38 [==============================] - 25s 661ms/step - loss: 0.5848 - accuracy: 0.7133 - val_loss: 0.5822 - val_accuracy: 0.7275\n",
      "Epoch 291/500\n",
      "38/38 [==============================] - 25s 651ms/step - loss: 0.5814 - accuracy: 0.7175 - val_loss: 0.5818 - val_accuracy: 0.7275\n",
      "Epoch 292/500\n",
      "38/38 [==============================] - 26s 675ms/step - loss: 0.5809 - accuracy: 0.7283 - val_loss: 0.5815 - val_accuracy: 0.7287\n",
      "Epoch 293/500\n",
      "38/38 [==============================] - 25s 650ms/step - loss: 0.5817 - accuracy: 0.7233 - val_loss: 0.5812 - val_accuracy: 0.7250\n",
      "Epoch 294/500\n",
      "38/38 [==============================] - 25s 671ms/step - loss: 0.5802 - accuracy: 0.7225 - val_loss: 0.5809 - val_accuracy: 0.7275\n",
      "Epoch 295/500\n",
      "38/38 [==============================] - 25s 663ms/step - loss: 0.5823 - accuracy: 0.7258 - val_loss: 0.5807 - val_accuracy: 0.7188\n",
      "Epoch 296/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.5798 - accuracy: 0.7258 - val_loss: 0.5803 - val_accuracy: 0.7262\n",
      "Epoch 297/500\n",
      "38/38 [==============================] - 26s 682ms/step - loss: 0.5775 - accuracy: 0.7325 - val_loss: 0.5800 - val_accuracy: 0.7287\n",
      "Epoch 298/500\n",
      "38/38 [==============================] - 25s 657ms/step - loss: 0.5766 - accuracy: 0.7217 - val_loss: 0.5797 - val_accuracy: 0.7275\n",
      "Epoch 299/500\n",
      "38/38 [==============================] - 25s 646ms/step - loss: 0.5767 - accuracy: 0.7283 - val_loss: 0.5794 - val_accuracy: 0.7275\n",
      "Epoch 300/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.5761 - accuracy: 0.7308 - val_loss: 0.5790 - val_accuracy: 0.7300\n",
      "Epoch 301/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.5760 - accuracy: 0.7317 - val_loss: 0.5788 - val_accuracy: 0.7250\n",
      "Epoch 302/500\n",
      "38/38 [==============================] - 25s 647ms/step - loss: 0.5774 - accuracy: 0.7225 - val_loss: 0.5784 - val_accuracy: 0.7287\n",
      "Epoch 303/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.5758 - accuracy: 0.7342 - val_loss: 0.5782 - val_accuracy: 0.7300\n",
      "Epoch 304/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.5769 - accuracy: 0.7158 - val_loss: 0.5779 - val_accuracy: 0.7250\n",
      "Epoch 305/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.5776 - accuracy: 0.7342 - val_loss: 0.5775 - val_accuracy: 0.7300\n",
      "Epoch 306/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.5752 - accuracy: 0.7275 - val_loss: 0.5772 - val_accuracy: 0.7337\n",
      "Epoch 307/500\n",
      "38/38 [==============================] - 25s 669ms/step - loss: 0.5742 - accuracy: 0.7200 - val_loss: 0.5769 - val_accuracy: 0.7237\n",
      "Epoch 308/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.5760 - accuracy: 0.7183 - val_loss: 0.5766 - val_accuracy: 0.7225\n",
      "Epoch 309/500\n",
      "38/38 [==============================] - 25s 650ms/step - loss: 0.5757 - accuracy: 0.7233 - val_loss: 0.5763 - val_accuracy: 0.7325\n",
      "Epoch 310/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.5764 - accuracy: 0.7242 - val_loss: 0.5761 - val_accuracy: 0.7250\n",
      "Epoch 311/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.5714 - accuracy: 0.7367 - val_loss: 0.5758 - val_accuracy: 0.7287\n",
      "Epoch 312/500\n",
      "38/38 [==============================] - 25s 660ms/step - loss: 0.5729 - accuracy: 0.7275 - val_loss: 0.5755 - val_accuracy: 0.7275\n",
      "Epoch 313/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.5757 - accuracy: 0.7342 - val_loss: 0.5752 - val_accuracy: 0.7262\n",
      "Epoch 314/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.5700 - accuracy: 0.7350 - val_loss: 0.5748 - val_accuracy: 0.7275\n",
      "Epoch 315/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.5723 - accuracy: 0.7250 - val_loss: 0.5745 - val_accuracy: 0.7325\n",
      "Epoch 316/500\n",
      "38/38 [==============================] - 30s 788ms/step - loss: 0.5746 - accuracy: 0.7167 - val_loss: 0.5743 - val_accuracy: 0.7325\n",
      "Epoch 317/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.5712 - accuracy: 0.7350 - val_loss: 0.5741 - val_accuracy: 0.7262\n",
      "Epoch 318/500\n",
      "38/38 [==============================] - 25s 660ms/step - loss: 0.5719 - accuracy: 0.7275 - val_loss: 0.5737 - val_accuracy: 0.7287\n",
      "Epoch 319/500\n",
      "38/38 [==============================] - 25s 665ms/step - loss: 0.5715 - accuracy: 0.7342 - val_loss: 0.5733 - val_accuracy: 0.7275\n",
      "Epoch 320/500\n",
      "38/38 [==============================] - 25s 653ms/step - loss: 0.5670 - accuracy: 0.7358 - val_loss: 0.5732 - val_accuracy: 0.7262\n",
      "Epoch 321/500\n",
      "38/38 [==============================] - 25s 658ms/step - loss: 0.5708 - accuracy: 0.7325 - val_loss: 0.5728 - val_accuracy: 0.7287\n",
      "Epoch 322/500\n",
      "38/38 [==============================] - 25s 664ms/step - loss: 0.5664 - accuracy: 0.7383 - val_loss: 0.5724 - val_accuracy: 0.7275\n",
      "Epoch 323/500\n",
      "38/38 [==============================] - 25s 651ms/step - loss: 0.5683 - accuracy: 0.7333 - val_loss: 0.5722 - val_accuracy: 0.7350\n",
      "Epoch 324/500\n",
      "38/38 [==============================] - 25s 662ms/step - loss: 0.5671 - accuracy: 0.7275 - val_loss: 0.5718 - val_accuracy: 0.7275\n",
      "Epoch 325/500\n",
      "38/38 [==============================] - 25s 651ms/step - loss: 0.5679 - accuracy: 0.7275 - val_loss: 0.5716 - val_accuracy: 0.7275\n",
      "Epoch 326/500\n",
      "38/38 [==============================] - 25s 651ms/step - loss: 0.5669 - accuracy: 0.7400 - val_loss: 0.5713 - val_accuracy: 0.7275\n",
      "Epoch 327/500\n",
      "38/38 [==============================] - 25s 661ms/step - loss: 0.5696 - accuracy: 0.7317 - val_loss: 0.5710 - val_accuracy: 0.7275\n",
      "Epoch 328/500\n",
      "38/38 [==============================] - 25s 663ms/step - loss: 0.5682 - accuracy: 0.7308 - val_loss: 0.5708 - val_accuracy: 0.7300\n",
      "Epoch 329/500\n",
      "38/38 [==============================] - 25s 663ms/step - loss: 0.5689 - accuracy: 0.7267 - val_loss: 0.5704 - val_accuracy: 0.7300\n",
      "Epoch 330/500\n",
      "38/38 [==============================] - 25s 654ms/step - loss: 0.5618 - accuracy: 0.7392 - val_loss: 0.5702 - val_accuracy: 0.7300\n",
      "Epoch 331/500\n",
      "38/38 [==============================] - 26s 674ms/step - loss: 0.5673 - accuracy: 0.7250 - val_loss: 0.5699 - val_accuracy: 0.7287\n",
      "Epoch 332/500\n",
      "38/38 [==============================] - 25s 662ms/step - loss: 0.5687 - accuracy: 0.7175 - val_loss: 0.5696 - val_accuracy: 0.7337\n",
      "Epoch 333/500\n",
      "38/38 [==============================] - 25s 659ms/step - loss: 0.5644 - accuracy: 0.7350 - val_loss: 0.5693 - val_accuracy: 0.7312\n",
      "Epoch 334/500\n",
      "38/38 [==============================] - 25s 661ms/step - loss: 0.5663 - accuracy: 0.7325 - val_loss: 0.5690 - val_accuracy: 0.7300\n",
      "Epoch 335/500\n",
      "38/38 [==============================] - 25s 656ms/step - loss: 0.5662 - accuracy: 0.7342 - val_loss: 0.5687 - val_accuracy: 0.7312\n",
      "Epoch 336/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.5695 - accuracy: 0.7208 - val_loss: 0.5685 - val_accuracy: 0.7300\n",
      "Epoch 337/500\n",
      "38/38 [==============================] - 25s 664ms/step - loss: 0.5632 - accuracy: 0.7308 - val_loss: 0.5681 - val_accuracy: 0.7312\n",
      "Epoch 338/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.5673 - accuracy: 0.7283 - val_loss: 0.5678 - val_accuracy: 0.7325\n",
      "Epoch 339/500\n",
      "38/38 [==============================] - 25s 664ms/step - loss: 0.5601 - accuracy: 0.7567 - val_loss: 0.5677 - val_accuracy: 0.7287\n",
      "Epoch 340/500\n",
      "38/38 [==============================] - 25s 663ms/step - loss: 0.5638 - accuracy: 0.7333 - val_loss: 0.5673 - val_accuracy: 0.7312\n",
      "Epoch 341/500\n",
      "38/38 [==============================] - 25s 653ms/step - loss: 0.5636 - accuracy: 0.7350 - val_loss: 0.5670 - val_accuracy: 0.7312\n",
      "Epoch 342/500\n",
      "38/38 [==============================] - 25s 669ms/step - loss: 0.5647 - accuracy: 0.7283 - val_loss: 0.5667 - val_accuracy: 0.7300\n",
      "Epoch 343/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.5639 - accuracy: 0.7308 - val_loss: 0.5665 - val_accuracy: 0.7287\n",
      "Epoch 344/500\n",
      "38/38 [==============================] - 25s 663ms/step - loss: 0.5625 - accuracy: 0.7358 - val_loss: 0.5662 - val_accuracy: 0.7287\n",
      "Epoch 345/500\n",
      "38/38 [==============================] - 25s 659ms/step - loss: 0.5618 - accuracy: 0.7292 - val_loss: 0.5659 - val_accuracy: 0.7300\n",
      "Epoch 346/500\n",
      "38/38 [==============================] - 25s 651ms/step - loss: 0.5628 - accuracy: 0.7383 - val_loss: 0.5656 - val_accuracy: 0.7287\n",
      "Epoch 347/500\n",
      "38/38 [==============================] - 26s 685ms/step - loss: 0.5638 - accuracy: 0.7300 - val_loss: 0.5653 - val_accuracy: 0.7300\n",
      "Epoch 348/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.5602 - accuracy: 0.7392 - val_loss: 0.5652 - val_accuracy: 0.7300\n",
      "Epoch 349/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.5572 - accuracy: 0.7467 - val_loss: 0.5648 - val_accuracy: 0.7325\n",
      "Epoch 350/500\n",
      "38/38 [==============================] - 25s 658ms/step - loss: 0.5585 - accuracy: 0.7392 - val_loss: 0.5645 - val_accuracy: 0.7325\n",
      "Epoch 351/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.5585 - accuracy: 0.7258 - val_loss: 0.5643 - val_accuracy: 0.7300\n",
      "Epoch 352/500\n",
      "38/38 [==============================] - 26s 674ms/step - loss: 0.5592 - accuracy: 0.7367 - val_loss: 0.5640 - val_accuracy: 0.7300\n",
      "Epoch 353/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.5575 - accuracy: 0.7358 - val_loss: 0.5638 - val_accuracy: 0.7300\n",
      "Epoch 354/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.5554 - accuracy: 0.7433 - val_loss: 0.5634 - val_accuracy: 0.7312\n",
      "Epoch 355/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.5567 - accuracy: 0.7367 - val_loss: 0.5631 - val_accuracy: 0.7275\n",
      "Epoch 356/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.5577 - accuracy: 0.7392 - val_loss: 0.5629 - val_accuracy: 0.7287\n",
      "Epoch 357/500\n",
      "38/38 [==============================] - 25s 658ms/step - loss: 0.5557 - accuracy: 0.7400 - val_loss: 0.5626 - val_accuracy: 0.7287\n",
      "Epoch 358/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.5585 - accuracy: 0.7400 - val_loss: 0.5623 - val_accuracy: 0.7287\n",
      "Epoch 359/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.5585 - accuracy: 0.7392 - val_loss: 0.5620 - val_accuracy: 0.7287\n",
      "Epoch 360/500\n",
      "38/38 [==============================] - 25s 647ms/step - loss: 0.5575 - accuracy: 0.7358 - val_loss: 0.5619 - val_accuracy: 0.7337\n",
      "Epoch 361/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.5555 - accuracy: 0.7392 - val_loss: 0.5615 - val_accuracy: 0.7275\n",
      "Epoch 362/500\n",
      "38/38 [==============================] - 25s 658ms/step - loss: 0.5567 - accuracy: 0.7392 - val_loss: 0.5612 - val_accuracy: 0.7275\n",
      "Epoch 363/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.5532 - accuracy: 0.7508 - val_loss: 0.5610 - val_accuracy: 0.7300\n",
      "Epoch 364/500\n",
      "38/38 [==============================] - 25s 653ms/step - loss: 0.5554 - accuracy: 0.7417 - val_loss: 0.5607 - val_accuracy: 0.7275\n",
      "Epoch 365/500\n",
      "38/38 [==============================] - 25s 665ms/step - loss: 0.5564 - accuracy: 0.7375 - val_loss: 0.5605 - val_accuracy: 0.7275\n",
      "Epoch 366/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.5569 - accuracy: 0.7308 - val_loss: 0.5602 - val_accuracy: 0.7287\n",
      "Epoch 367/500\n",
      "38/38 [==============================] - 26s 678ms/step - loss: 0.5560 - accuracy: 0.7417 - val_loss: 0.5600 - val_accuracy: 0.7275\n",
      "Epoch 368/500\n",
      "38/38 [==============================] - 24s 647ms/step - loss: 0.5544 - accuracy: 0.7392 - val_loss: 0.5597 - val_accuracy: 0.7287\n",
      "Epoch 369/500\n",
      "38/38 [==============================] - 25s 660ms/step - loss: 0.5568 - accuracy: 0.7408 - val_loss: 0.5595 - val_accuracy: 0.7312\n",
      "Epoch 370/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.5580 - accuracy: 0.7342 - val_loss: 0.5591 - val_accuracy: 0.7287\n",
      "Epoch 371/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.5518 - accuracy: 0.7417 - val_loss: 0.5589 - val_accuracy: 0.7262\n",
      "Epoch 372/500\n",
      "38/38 [==============================] - 25s 661ms/step - loss: 0.5547 - accuracy: 0.7458 - val_loss: 0.5587 - val_accuracy: 0.7262\n",
      "Epoch 373/500\n",
      "38/38 [==============================] - 25s 653ms/step - loss: 0.5530 - accuracy: 0.7358 - val_loss: 0.5583 - val_accuracy: 0.7262\n",
      "Epoch 374/500\n",
      "38/38 [==============================] - 25s 670ms/step - loss: 0.5502 - accuracy: 0.7442 - val_loss: 0.5581 - val_accuracy: 0.7250\n",
      "Epoch 375/500\n",
      "38/38 [==============================] - 25s 649ms/step - loss: 0.5511 - accuracy: 0.7483 - val_loss: 0.5580 - val_accuracy: 0.7350\n",
      "Epoch 376/500\n",
      "38/38 [==============================] - 25s 670ms/step - loss: 0.5525 - accuracy: 0.7383 - val_loss: 0.5578 - val_accuracy: 0.7325\n",
      "Epoch 377/500\n",
      "38/38 [==============================] - 25s 660ms/step - loss: 0.5523 - accuracy: 0.7342 - val_loss: 0.5574 - val_accuracy: 0.7287\n",
      "Epoch 378/500\n",
      "38/38 [==============================] - 25s 652ms/step - loss: 0.5534 - accuracy: 0.7342 - val_loss: 0.5572 - val_accuracy: 0.7287\n",
      "Epoch 379/500\n",
      "38/38 [==============================] - 26s 677ms/step - loss: 0.5484 - accuracy: 0.7450 - val_loss: 0.5569 - val_accuracy: 0.7300\n",
      "Epoch 380/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.5519 - accuracy: 0.7375 - val_loss: 0.5568 - val_accuracy: 0.7362\n",
      "Epoch 381/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.5508 - accuracy: 0.7500 - val_loss: 0.5564 - val_accuracy: 0.7287\n",
      "Epoch 382/500\n",
      "38/38 [==============================] - 25s 662ms/step - loss: 0.5485 - accuracy: 0.7467 - val_loss: 0.5562 - val_accuracy: 0.7287\n",
      "Epoch 383/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.5476 - accuracy: 0.7425 - val_loss: 0.5560 - val_accuracy: 0.7312\n",
      "Epoch 384/500\n",
      "38/38 [==============================] - 25s 652ms/step - loss: 0.5462 - accuracy: 0.7617 - val_loss: 0.5557 - val_accuracy: 0.7325\n",
      "Epoch 385/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.5493 - accuracy: 0.7400 - val_loss: 0.5554 - val_accuracy: 0.7287\n",
      "Epoch 386/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.5496 - accuracy: 0.7400 - val_loss: 0.5552 - val_accuracy: 0.7325\n",
      "Epoch 387/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.5490 - accuracy: 0.7408 - val_loss: 0.5549 - val_accuracy: 0.7325\n",
      "Epoch 388/500\n",
      "38/38 [==============================] - 25s 650ms/step - loss: 0.5491 - accuracy: 0.7492 - val_loss: 0.5546 - val_accuracy: 0.7337\n",
      "Epoch 389/500\n",
      "38/38 [==============================] - 26s 696ms/step - loss: 0.5478 - accuracy: 0.7375 - val_loss: 0.5544 - val_accuracy: 0.7312\n",
      "Epoch 390/500\n",
      "38/38 [==============================] - 25s 650ms/step - loss: 0.5493 - accuracy: 0.7417 - val_loss: 0.5542 - val_accuracy: 0.7325\n",
      "Epoch 391/500\n",
      "38/38 [==============================] - 25s 652ms/step - loss: 0.5474 - accuracy: 0.7517 - val_loss: 0.5539 - val_accuracy: 0.7300\n",
      "Epoch 392/500\n",
      "38/38 [==============================] - 25s 668ms/step - loss: 0.5472 - accuracy: 0.7442 - val_loss: 0.5537 - val_accuracy: 0.7312\n",
      "Epoch 393/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.5462 - accuracy: 0.7417 - val_loss: 0.5535 - val_accuracy: 0.7300\n",
      "Epoch 394/500\n",
      "38/38 [==============================] - 25s 650ms/step - loss: 0.5469 - accuracy: 0.7442 - val_loss: 0.5533 - val_accuracy: 0.7325\n",
      "Epoch 395/500\n",
      "38/38 [==============================] - 25s 664ms/step - loss: 0.5481 - accuracy: 0.7383 - val_loss: 0.5530 - val_accuracy: 0.7312\n",
      "Epoch 396/500\n",
      "38/38 [==============================] - 25s 654ms/step - loss: 0.5470 - accuracy: 0.7383 - val_loss: 0.5528 - val_accuracy: 0.7325\n",
      "Epoch 397/500\n",
      "38/38 [==============================] - 25s 662ms/step - loss: 0.5485 - accuracy: 0.7417 - val_loss: 0.5526 - val_accuracy: 0.7350\n",
      "Epoch 398/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.5477 - accuracy: 0.7450 - val_loss: 0.5523 - val_accuracy: 0.7300\n",
      "Epoch 399/500\n",
      "38/38 [==============================] - 25s 652ms/step - loss: 0.5455 - accuracy: 0.7442 - val_loss: 0.5520 - val_accuracy: 0.7300\n",
      "Epoch 400/500\n",
      "38/38 [==============================] - 25s 666ms/step - loss: 0.5464 - accuracy: 0.7325 - val_loss: 0.5520 - val_accuracy: 0.7350\n",
      "Epoch 401/500\n",
      "38/38 [==============================] - 25s 671ms/step - loss: 0.5431 - accuracy: 0.7533 - val_loss: 0.5516 - val_accuracy: 0.7312\n",
      "Epoch 402/500\n",
      "38/38 [==============================] - 25s 664ms/step - loss: 0.5433 - accuracy: 0.7500 - val_loss: 0.5514 - val_accuracy: 0.7350\n",
      "Epoch 403/500\n",
      "38/38 [==============================] - 26s 676ms/step - loss: 0.5391 - accuracy: 0.7550 - val_loss: 0.5512 - val_accuracy: 0.7350\n",
      "Epoch 404/500\n",
      "38/38 [==============================] - 25s 647ms/step - loss: 0.5456 - accuracy: 0.7392 - val_loss: 0.5510 - val_accuracy: 0.7362\n",
      "Epoch 405/500\n",
      "38/38 [==============================] - 25s 659ms/step - loss: 0.5431 - accuracy: 0.7483 - val_loss: 0.5506 - val_accuracy: 0.7312\n",
      "Epoch 406/500\n",
      "38/38 [==============================] - 25s 649ms/step - loss: 0.5421 - accuracy: 0.7483 - val_loss: 0.5504 - val_accuracy: 0.7325\n",
      "Epoch 407/500\n",
      "38/38 [==============================] - 25s 662ms/step - loss: 0.5430 - accuracy: 0.7425 - val_loss: 0.5501 - val_accuracy: 0.7300\n",
      "Epoch 408/500\n",
      "38/38 [==============================] - 25s 661ms/step - loss: 0.5444 - accuracy: 0.7475 - val_loss: 0.5499 - val_accuracy: 0.7312\n",
      "Epoch 409/500\n",
      "38/38 [==============================] - 25s 653ms/step - loss: 0.5415 - accuracy: 0.7517 - val_loss: 0.5496 - val_accuracy: 0.7325\n",
      "Epoch 410/500\n",
      "38/38 [==============================] - 26s 691ms/step - loss: 0.5423 - accuracy: 0.7475 - val_loss: 0.5494 - val_accuracy: 0.7300\n",
      "Epoch 411/500\n",
      "38/38 [==============================] - 25s 653ms/step - loss: 0.5435 - accuracy: 0.7492 - val_loss: 0.5492 - val_accuracy: 0.7300\n",
      "Epoch 412/500\n",
      "38/38 [==============================] - 26s 677ms/step - loss: 0.5419 - accuracy: 0.7475 - val_loss: 0.5490 - val_accuracy: 0.7312\n",
      "Epoch 413/500\n",
      "38/38 [==============================] - 25s 657ms/step - loss: 0.5441 - accuracy: 0.7442 - val_loss: 0.5488 - val_accuracy: 0.7300\n",
      "Epoch 414/500\n",
      "38/38 [==============================] - 26s 694ms/step - loss: 0.5432 - accuracy: 0.7358 - val_loss: 0.5486 - val_accuracy: 0.7362\n",
      "Epoch 415/500\n",
      "38/38 [==============================] - 26s 688ms/step - loss: 0.5387 - accuracy: 0.7483 - val_loss: 0.5484 - val_accuracy: 0.7325\n",
      "Epoch 416/500\n",
      "38/38 [==============================] - 25s 651ms/step - loss: 0.5430 - accuracy: 0.7425 - val_loss: 0.5481 - val_accuracy: 0.7325\n",
      "Epoch 417/500\n",
      "38/38 [==============================] - 26s 679ms/step - loss: 0.5427 - accuracy: 0.7417 - val_loss: 0.5480 - val_accuracy: 0.7325\n",
      "Epoch 418/500\n",
      "38/38 [==============================] - 25s 650ms/step - loss: 0.5396 - accuracy: 0.7467 - val_loss: 0.5477 - val_accuracy: 0.7362\n",
      "Epoch 419/500\n",
      "38/38 [==============================] - 25s 656ms/step - loss: 0.5372 - accuracy: 0.7542 - val_loss: 0.5475 - val_accuracy: 0.7325\n",
      "Epoch 420/500\n",
      "38/38 [==============================] - 25s 652ms/step - loss: 0.5373 - accuracy: 0.7433 - val_loss: 0.5473 - val_accuracy: 0.7350\n",
      "Epoch 421/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.5392 - accuracy: 0.7525 - val_loss: 0.5471 - val_accuracy: 0.7350\n",
      "Epoch 422/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.5418 - accuracy: 0.7358 - val_loss: 0.5469 - val_accuracy: 0.7350\n",
      "Epoch 423/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.5390 - accuracy: 0.7458 - val_loss: 0.5467 - val_accuracy: 0.7350\n",
      "Epoch 424/500\n",
      "38/38 [==============================] - 25s 657ms/step - loss: 0.5359 - accuracy: 0.7475 - val_loss: 0.5464 - val_accuracy: 0.7375\n",
      "Epoch 425/500\n",
      "38/38 [==============================] - 25s 647ms/step - loss: 0.5395 - accuracy: 0.7458 - val_loss: 0.5463 - val_accuracy: 0.7350\n",
      "Epoch 426/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.5352 - accuracy: 0.7500 - val_loss: 0.5460 - val_accuracy: 0.7362\n",
      "Epoch 427/500\n",
      "38/38 [==============================] - 25s 651ms/step - loss: 0.5389 - accuracy: 0.7525 - val_loss: 0.5458 - val_accuracy: 0.7362\n",
      "Epoch 428/500\n",
      "38/38 [==============================] - 24s 639ms/step - loss: 0.5383 - accuracy: 0.7567 - val_loss: 0.5460 - val_accuracy: 0.7437\n",
      "Epoch 429/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.5378 - accuracy: 0.7592 - val_loss: 0.5454 - val_accuracy: 0.7362\n",
      "Epoch 430/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.5380 - accuracy: 0.7592 - val_loss: 0.5451 - val_accuracy: 0.7362\n",
      "Epoch 431/500\n",
      "38/38 [==============================] - 24s 636ms/step - loss: 0.5372 - accuracy: 0.7508 - val_loss: 0.5450 - val_accuracy: 0.7350\n",
      "Epoch 432/500\n",
      "38/38 [==============================] - 25s 651ms/step - loss: 0.5391 - accuracy: 0.7333 - val_loss: 0.5447 - val_accuracy: 0.7350\n",
      "Epoch 433/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.5367 - accuracy: 0.7433 - val_loss: 0.5445 - val_accuracy: 0.7362\n",
      "Epoch 434/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.5382 - accuracy: 0.7417 - val_loss: 0.5443 - val_accuracy: 0.7362\n",
      "Epoch 435/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.5354 - accuracy: 0.7408 - val_loss: 0.5441 - val_accuracy: 0.7362\n",
      "Epoch 436/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.5351 - accuracy: 0.7508 - val_loss: 0.5440 - val_accuracy: 0.7350\n",
      "Epoch 437/500\n",
      "38/38 [==============================] - 25s 656ms/step - loss: 0.5324 - accuracy: 0.7500 - val_loss: 0.5437 - val_accuracy: 0.7350\n",
      "Epoch 438/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.5344 - accuracy: 0.7525 - val_loss: 0.5435 - val_accuracy: 0.7375\n",
      "Epoch 439/500\n",
      "38/38 [==============================] - 25s 656ms/step - loss: 0.5346 - accuracy: 0.7583 - val_loss: 0.5433 - val_accuracy: 0.7375\n",
      "Epoch 440/500\n",
      "38/38 [==============================] - 24s 637ms/step - loss: 0.5341 - accuracy: 0.7508 - val_loss: 0.5431 - val_accuracy: 0.7375\n",
      "Epoch 441/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.5329 - accuracy: 0.7558 - val_loss: 0.5428 - val_accuracy: 0.7375\n",
      "Epoch 442/500\n",
      "38/38 [==============================] - 25s 659ms/step - loss: 0.5339 - accuracy: 0.7492 - val_loss: 0.5427 - val_accuracy: 0.7362\n",
      "Epoch 443/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.5341 - accuracy: 0.7558 - val_loss: 0.5427 - val_accuracy: 0.7412\n",
      "Epoch 444/500\n",
      "38/38 [==============================] - 24s 647ms/step - loss: 0.5329 - accuracy: 0.7558 - val_loss: 0.5423 - val_accuracy: 0.7375\n",
      "Epoch 445/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.5332 - accuracy: 0.7558 - val_loss: 0.5421 - val_accuracy: 0.7362\n",
      "Epoch 446/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.5308 - accuracy: 0.7542 - val_loss: 0.5418 - val_accuracy: 0.7375\n",
      "Epoch 447/500\n",
      "38/38 [==============================] - 25s 659ms/step - loss: 0.5315 - accuracy: 0.7558 - val_loss: 0.5418 - val_accuracy: 0.7400\n",
      "Epoch 448/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.5351 - accuracy: 0.7533 - val_loss: 0.5415 - val_accuracy: 0.7400\n",
      "Epoch 449/500\n",
      "38/38 [==============================] - 25s 669ms/step - loss: 0.5325 - accuracy: 0.7525 - val_loss: 0.5412 - val_accuracy: 0.7387\n",
      "Epoch 450/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.5328 - accuracy: 0.7442 - val_loss: 0.5410 - val_accuracy: 0.7362\n",
      "Epoch 451/500\n",
      "38/38 [==============================] - 25s 668ms/step - loss: 0.5292 - accuracy: 0.7558 - val_loss: 0.5408 - val_accuracy: 0.7375\n",
      "Epoch 452/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.5314 - accuracy: 0.7450 - val_loss: 0.5407 - val_accuracy: 0.7350\n",
      "Epoch 453/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.5314 - accuracy: 0.7483 - val_loss: 0.5404 - val_accuracy: 0.7387\n",
      "Epoch 454/500\n",
      "38/38 [==============================] - 25s 652ms/step - loss: 0.5295 - accuracy: 0.7558 - val_loss: 0.5403 - val_accuracy: 0.7400\n",
      "Epoch 455/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.5311 - accuracy: 0.7525 - val_loss: 0.5401 - val_accuracy: 0.7375\n",
      "Epoch 456/500\n",
      "38/38 [==============================] - 25s 649ms/step - loss: 0.5284 - accuracy: 0.7467 - val_loss: 0.5400 - val_accuracy: 0.7387\n",
      "Epoch 457/500\n",
      "38/38 [==============================] - 25s 649ms/step - loss: 0.5321 - accuracy: 0.7408 - val_loss: 0.5397 - val_accuracy: 0.7362\n",
      "Epoch 458/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.5309 - accuracy: 0.7508 - val_loss: 0.5395 - val_accuracy: 0.7387\n",
      "Epoch 459/500\n",
      "38/38 [==============================] - 24s 647ms/step - loss: 0.5295 - accuracy: 0.7550 - val_loss: 0.5394 - val_accuracy: 0.7400\n",
      "Epoch 460/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.5313 - accuracy: 0.7425 - val_loss: 0.5391 - val_accuracy: 0.7400\n",
      "Epoch 461/500\n",
      "38/38 [==============================] - 29s 773ms/step - loss: 0.5279 - accuracy: 0.7600 - val_loss: 0.5390 - val_accuracy: 0.7387\n",
      "Epoch 462/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.5277 - accuracy: 0.7550 - val_loss: 0.5388 - val_accuracy: 0.7400\n",
      "Epoch 463/500\n",
      "38/38 [==============================] - 26s 677ms/step - loss: 0.5287 - accuracy: 0.7550 - val_loss: 0.5386 - val_accuracy: 0.7400\n",
      "Epoch 464/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.5306 - accuracy: 0.7567 - val_loss: 0.5384 - val_accuracy: 0.7400\n",
      "Epoch 465/500\n",
      "38/38 [==============================] - 25s 655ms/step - loss: 0.5293 - accuracy: 0.7450 - val_loss: 0.5382 - val_accuracy: 0.7387\n",
      "Epoch 466/500\n",
      "38/38 [==============================] - 25s 652ms/step - loss: 0.5266 - accuracy: 0.7608 - val_loss: 0.5381 - val_accuracy: 0.7400\n",
      "Epoch 467/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.5264 - accuracy: 0.7442 - val_loss: 0.5378 - val_accuracy: 0.7387\n",
      "Epoch 468/500\n",
      "38/38 [==============================] - 24s 645ms/step - loss: 0.5283 - accuracy: 0.7492 - val_loss: 0.5378 - val_accuracy: 0.7412\n",
      "Epoch 469/500\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.5286 - accuracy: 0.7467 - val_loss: 0.5375 - val_accuracy: 0.7387\n",
      "Epoch 470/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.5289 - accuracy: 0.7450 - val_loss: 0.5374 - val_accuracy: 0.7375\n",
      "Epoch 471/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.5254 - accuracy: 0.7583 - val_loss: 0.5374 - val_accuracy: 0.7425\n",
      "Epoch 472/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.5285 - accuracy: 0.7525 - val_loss: 0.5369 - val_accuracy: 0.7375\n",
      "Epoch 473/500\n",
      "38/38 [==============================] - 26s 699ms/step - loss: 0.5252 - accuracy: 0.7658 - val_loss: 0.5368 - val_accuracy: 0.7387\n",
      "Epoch 474/500\n",
      "38/38 [==============================] - 25s 650ms/step - loss: 0.5274 - accuracy: 0.7592 - val_loss: 0.5366 - val_accuracy: 0.7387\n",
      "Epoch 475/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.5227 - accuracy: 0.7575 - val_loss: 0.5364 - val_accuracy: 0.7362\n",
      "Epoch 476/500\n",
      "38/38 [==============================] - 25s 650ms/step - loss: 0.5226 - accuracy: 0.7508 - val_loss: 0.5362 - val_accuracy: 0.7375\n",
      "Epoch 477/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.5223 - accuracy: 0.7550 - val_loss: 0.5361 - val_accuracy: 0.7387\n",
      "Epoch 478/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.5248 - accuracy: 0.7542 - val_loss: 0.5359 - val_accuracy: 0.7362\n",
      "Epoch 479/500\n",
      "38/38 [==============================] - 24s 643ms/step - loss: 0.5276 - accuracy: 0.7508 - val_loss: 0.5358 - val_accuracy: 0.7400\n",
      "Epoch 480/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.5261 - accuracy: 0.7500 - val_loss: 0.5355 - val_accuracy: 0.7362\n",
      "Epoch 481/500\n",
      "38/38 [==============================] - 25s 650ms/step - loss: 0.5246 - accuracy: 0.7583 - val_loss: 0.5355 - val_accuracy: 0.7425\n",
      "Epoch 482/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.5238 - accuracy: 0.7492 - val_loss: 0.5352 - val_accuracy: 0.7387\n",
      "Epoch 483/500\n",
      "38/38 [==============================] - 24s 646ms/step - loss: 0.5253 - accuracy: 0.7467 - val_loss: 0.5351 - val_accuracy: 0.7375\n",
      "Epoch 484/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.5224 - accuracy: 0.7533 - val_loss: 0.5350 - val_accuracy: 0.7412\n",
      "Epoch 485/500\n",
      "38/38 [==============================] - 25s 662ms/step - loss: 0.5262 - accuracy: 0.7533 - val_loss: 0.5347 - val_accuracy: 0.7375\n",
      "Epoch 486/500\n",
      "38/38 [==============================] - 25s 647ms/step - loss: 0.5223 - accuracy: 0.7567 - val_loss: 0.5345 - val_accuracy: 0.7387\n",
      "Epoch 487/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.5216 - accuracy: 0.7567 - val_loss: 0.5344 - val_accuracy: 0.7437\n",
      "Epoch 488/500\n",
      "38/38 [==============================] - 24s 647ms/step - loss: 0.5204 - accuracy: 0.7517 - val_loss: 0.5342 - val_accuracy: 0.7400\n",
      "Epoch 489/500\n",
      "38/38 [==============================] - 25s 650ms/step - loss: 0.5217 - accuracy: 0.7558 - val_loss: 0.5341 - val_accuracy: 0.7387\n",
      "Epoch 490/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.5245 - accuracy: 0.7558 - val_loss: 0.5339 - val_accuracy: 0.7462\n",
      "Epoch 491/500\n",
      "38/38 [==============================] - 24s 644ms/step - loss: 0.5258 - accuracy: 0.7467 - val_loss: 0.5337 - val_accuracy: 0.7387\n",
      "Epoch 492/500\n",
      "38/38 [==============================] - 24s 640ms/step - loss: 0.5222 - accuracy: 0.7500 - val_loss: 0.5338 - val_accuracy: 0.7475\n",
      "Epoch 493/500\n",
      "38/38 [==============================] - 25s 671ms/step - loss: 0.5212 - accuracy: 0.7575 - val_loss: 0.5334 - val_accuracy: 0.7450\n",
      "Epoch 494/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.5207 - accuracy: 0.7525 - val_loss: 0.5332 - val_accuracy: 0.7400\n",
      "Epoch 495/500\n",
      "38/38 [==============================] - 25s 654ms/step - loss: 0.5190 - accuracy: 0.7500 - val_loss: 0.5329 - val_accuracy: 0.7450\n",
      "Epoch 496/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.5205 - accuracy: 0.7575 - val_loss: 0.5328 - val_accuracy: 0.7462\n",
      "Epoch 497/500\n",
      "38/38 [==============================] - 24s 642ms/step - loss: 0.5192 - accuracy: 0.7608 - val_loss: 0.5325 - val_accuracy: 0.7350\n",
      "Epoch 498/500\n",
      "38/38 [==============================] - 25s 658ms/step - loss: 0.5200 - accuracy: 0.7550 - val_loss: 0.5323 - val_accuracy: 0.7350\n",
      "Epoch 499/500\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 0.5199 - accuracy: 0.7592 - val_loss: 0.5322 - val_accuracy: 0.7400\n",
      "Epoch 500/500\n",
      "38/38 [==============================] - 25s 648ms/step - loss: 0.5199 - accuracy: 0.7633 - val_loss: 0.5320 - val_accuracy: 0.7362\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs = 500 , validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d2572",
   "metadata": {},
   "source": [
    "Write model to JSON file so that it can be loaded from disk within the MelaMate application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7613bc6a-d44b-47e4-9187-fd9c1e1b40db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabda4b0",
   "metadata": {},
   "source": [
    "Write model weights to H5 file so that it can be loaded from disk within the MelaMate application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bec3de12-6817-410b-bb13-865f6c01e1cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b77028",
   "metadata": {},
   "source": [
    "Test loading the file from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38483a63-c6bf-4204-a126-49538e84102e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2fd7e261cf4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load json and create model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mjson_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mloaded_model_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mloaded_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.json'"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0042052a",
   "metadata": {},
   "source": [
    "Test compiling model loaded from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cbbccd4-f2e2-438a-a618-ef040a8f983d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9fc3069a9e90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.000001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loaded_model' is not defined"
     ]
    }
   ],
   "source": [
    "opt = Adam(learning_rate=0.000001)\n",
    "loaded_model.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])\n",
    "score = loaded_model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e981d",
   "metadata": {},
   "source": [
    "Get predictions of model on each testing data point, both predicted class probability and predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48cd5643-984e-40ee-9707-ad1c0bf6eef2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 4s 152ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_prob=loaded_model.predict(x_test)\n",
    "\n",
    "predict_classes=np.argmax(predict_prob,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e5cea",
   "metadata": {},
   "source": [
    "Compare the predicted and actual classes for each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35fa45e5-7e6f-40b7-9c0a-8447d818493e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = list()\n",
    "for i in range(0, len(x_test)):\n",
    "    if predict_prob[i][1] < 0.5:\n",
    "        p = 0\n",
    "    else:\n",
    "        p = 1\n",
    "    if p == y_test[i]:\n",
    "        o = True\n",
    "    else:\n",
    "        o = False\n",
    "    x = [y_test[i], predict_prob[i][1], p, o]\n",
    "    results.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9080f3",
   "metadata": {},
   "source": [
    "Get the list of predictions that were incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cea03606-60ea-476d-a380-a3d7cc23a359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "errors = list()\n",
    "\n",
    "for i in range(0, len(results)):\n",
    "    if not results[i][3]:\n",
    "        e = [results[i][0], results[i][1]]\n",
    "        errors.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a299f",
   "metadata": {},
   "source": [
    "Plot the distribution of predicted probability of melanoma for datapoints that were incorrectly listed as melanoma but are actually not melanoma (false postives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b4c2f52-016c-4444-b960-635d86f85f35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "errors_df = pd.DataFrame(errors, columns = ['Target', 'Prediction'])\n",
    "e = errors_df[errors_df['Target'] == 0]\n",
    "\n",
    "plt.hist(e['Prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff996dd3",
   "metadata": {},
   "source": [
    "Plot the distribution of predicted probability of melanoma for datapoints that were incorrectly listed as not melanoma but are actually melanoma (false negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb1dd8e2-5ff3-4c71-8bf4-d3b3974dbd32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "errors_df = pd.DataFrame(errors, columns = ['Target', 'Prediction'])\n",
    "e = errors_df[errors_df['Target'] == 1]\n",
    "\n",
    "plt.hist(e['Prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae99ad-aec8-4fd6-be2e-3d90a862f680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
